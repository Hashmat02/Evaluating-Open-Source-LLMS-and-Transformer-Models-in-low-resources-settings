{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-18T16:33:57.525660Z",
     "iopub.status.busy": "2024-12-18T16:33:57.525300Z",
     "iopub.status.idle": "2024-12-18T16:34:07.371060Z",
     "shell.execute_reply": "2024-12-18T16:34:07.369993Z",
     "shell.execute_reply.started": "2024-12-18T16:33:57.525618Z"
    },
    "id": "rIIh2awoCKMJ",
    "outputId": "32a9dde5-319c-43fc-e58a-6a4abaa97332",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets transformers torch\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:07.372949Z",
     "iopub.status.busy": "2024-12-18T16:34:07.372551Z",
     "iopub.status.idle": "2024-12-18T16:34:08.544329Z",
     "shell.execute_reply": "2024-12-18T16:34:08.543348Z",
     "shell.execute_reply.started": "2024-12-18T16:34:07.372897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Train and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Data = \"/kaggle/input/sindhi-qa/cleaned_SQuAD_Sindhi.csv\"\n",
    "data = pd.read_csv(Data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=40)\n",
    "train_data.to_csv(\"/kaggle/working/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"/kaggle/working/test_data.csv\", index=False)\n",
    "print(\"Dataset split complete. Train and test datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:08.546292Z",
     "iopub.status.busy": "2024-12-18T16:34:08.546029Z",
     "iopub.status.idle": "2024-12-18T16:34:26.888919Z",
     "shell.execute_reply": "2024-12-18T16:34:26.888195Z",
     "shell.execute_reply.started": "2024-12-18T16:34:08.546264Z"
    },
    "id": "zGepLnupWOEj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForQuestionAnswering, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.890334Z",
     "iopub.status.busy": "2024-12-18T16:34:26.889850Z",
     "iopub.status.idle": "2024-12-18T16:34:26.898433Z",
     "shell.execute_reply": "2024-12-18T16:34:26.897459Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.890307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_split_data(\n",
    "    input_csv, \n",
    "    train_ratio=0.7, \n",
    "    test_ratio=0.15, \n",
    "    random_seed=42\n",
    "):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    total_samples = len(df)\n",
    "    train_end = int(total_samples * train_ratio)\n",
    "    val_end = train_end + int(total_samples * test_ratio)\n",
    "    \n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "    \n",
    "    def transform_subset(subset_df):\n",
    "        records = []\n",
    "        for _, row in tqdm(subset_df.iterrows(), total=len(subset_df), \n",
    "                            desc=\"Transforming data\"):\n",
    "            context = ' '.join(row['context']) if isinstance(row['context'], list) else row['context']\n",
    "            \n",
    "            answer_start = context.find(row['answer']) \\\n",
    "                if not row['is_impossible'] else -1\n",
    "            \n",
    "            record = {\n",
    "                \"id\": row.get('id', ''),\n",
    "                \"title\": row.get('title', ''),\n",
    "                \"context\": context,\n",
    "                \"question\": row['question'],\n",
    "                \"answer\": row['answer'],\n",
    "                \"answer_start\": answer_start,\n",
    "                \"is_impossible\": row['is_impossible']\n",
    "            }\n",
    "            records.append(record)\n",
    "        return records\n",
    "    \n",
    "    train_records = transform_subset(train_df)\n",
    "    val_records = transform_subset(val_df)\n",
    "    test_records = transform_subset(test_df)\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(pd.DataFrame(train_records))\n",
    "    val_dataset = Dataset.from_pandas(pd.DataFrame(val_records))\n",
    "    test_dataset = Dataset.from_pandas(pd.DataFrame(test_records))\n",
    "    \n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset, \n",
    "        \"validation\": val_dataset, \n",
    "        \"test\": test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.899864Z",
     "iopub.status.busy": "2024-12-18T16:34:26.899611Z",
     "iopub.status.idle": "2024-12-18T16:34:26.923722Z",
     "shell.execute_reply": "2024-12-18T16:34:26.923020Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.899838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(tokenizer, examples, max_length=384, stride=128):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    answer_starts = examples[\"answer_start\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer_starts[sample_idx]\n",
    "        end_char = answer_starts[sample_idx] + len(answer)\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "        \n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            \n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.925036Z",
     "iopub.status.busy": "2024-12-18T16:34:26.924798Z",
     "iopub.status.idle": "2024-12-18T16:34:26.938860Z",
     "shell.execute_reply": "2024-12-18T16:34:26.938142Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.925012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_qa_model(\n",
    "    data, \n",
    "    model_name=\"roberta-base\", \n",
    "    num_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    batch_size=32\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    processed_data = data.map(\n",
    "        lambda x: preprocess_function(tokenizer, x), \n",
    "        batched=True, \n",
    "        remove_columns=data[\"train\"].column_names\n",
    "    )\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,  \n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_data[\"train\"],\n",
    "        eval_dataset=processed_data[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    model.save_pretrained(\"./fine_tuned_model\")\n",
    "    tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "    try:\n",
    "        shutil.make_archive(\"./fine_tuned_model_archive\", 'zip', \"./fine_tuned_model\")\n",
    "        print(f\"Model saved and zipped to ./fine_tuned_model_archive.zip\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating zip archive: {e}\")\n",
    "    \n",
    "    return trainer, tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:55.031620Z",
     "iopub.status.busy": "2024-12-18T16:34:55.031034Z",
     "iopub.status.idle": "2024-12-18T17:09:53.775612Z",
     "shell.execute_reply": "2024-12-18T17:09:53.774715Z",
     "shell.execute_reply.started": "2024-12-18T16:34:55.031585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming data: 100%|██████████| 2800/2800 [00:00<00:00, 16677.63it/s]\n",
      "Transforming data: 100%|██████████| 600/600 [00:00<00:00, 17050.94it/s]\n",
      "Transforming data: 100%|██████████| 600/600 [00:00<00:00, 16459.87it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbeb8e7b99f40d0b1ea1e9859a979b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8699690820f045b89dc92a725195695d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac494abce694cb5ba4d552e51916550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259f1998df974dbd86efbf9893d26454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e22bb828ecb4e839bd1f2cb31daef72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7062c7f30594c459b8dcdfb356f4042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefb26d2c92f412898e0eb5c1f74ae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ba48c13a534e80914e6819564d99c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3f8061b8254b44965566d87c573ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_49/612374700.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241218_163518-g0v6al28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/mirzaarham796-lums/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mirzaarham796-lums/huggingface' target=\"_blank\">https://wandb.ai/mirzaarham796-lums/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28' target=\"_blank\">https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 33:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.336278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.322926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.321187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.313713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.311321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved and zipped to ./fine_tuned_model_archive.zip\n"
     ]
    }
   ],
   "source": [
    "input_csv = \"/kaggle/working/train_data.csv\"\n",
    "dataset = load_and_split_data(input_csv)\n",
    "trainer, tokenizer, model = train_qa_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:11:17.864379Z",
     "iopub.status.busy": "2024-12-18T17:11:17.863560Z",
     "iopub.status.idle": "2024-12-18T17:11:17.933891Z",
     "shell.execute_reply": "2024-12-18T17:11:17.933227Z",
     "shell.execute_reply.started": "2024-12-18T17:11:17.864346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "def calculate_exact_match(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)  \n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)  \n",
    "    return 1 if predicted_answer.strip().lower() == actual_answer.strip().lower() else 0\n",
    "\n",
    "def calculate_f1_score(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)\n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)\n",
    "    \n",
    "    pred_tokens = set(predicted_answer.strip().lower().split())\n",
    "    actual_tokens = set(actual_answer.strip().lower().split())\n",
    "    precision = len(pred_tokens & actual_tokens) / len(pred_tokens) if pred_tokens else 0\n",
    "    recall = len(pred_tokens & actual_tokens) / len(actual_tokens) if actual_tokens else 0\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "def calculate_cosine_similarity(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)\n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)\n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform([predicted_answer, actual_answer])\n",
    "    cos_sim = cosine_similarity(vectorizer[0:1], vectorizer[1:2])\n",
    "    return cos_sim[0][0]\n",
    "\n",
    "def display_results_qa_model(tokenizer, model, dataset, num_examples=5):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    examples = dataset[\"validation\"].select(range(num_examples))\n",
    "    \n",
    "    total_exact_match = 0\n",
    "    total_f1_score = 0\n",
    "    total_cosine_sim = 0\n",
    "    \n",
    "    print(\"Evaluating on 5 examples...\\n\")\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        actual_answer = example['answer'] \n",
    "        prediction = qa_pipeline(question=question, context=context)\n",
    "        predicted_answer = prediction['answer']\n",
    "        predicted_answer = predicted_answer.replace(\"••\", \"\")\n",
    "\n",
    "        exact_match = calculate_exact_match(predicted_answer, actual_answer)\n",
    "        f1_score = calculate_f1_score(predicted_answer, actual_answer)\n",
    "        cosine_sim = calculate_cosine_similarity(predicted_answer, actual_answer)\n",
    "        \n",
    "        total_exact_match += exact_match\n",
    "        total_f1_score += f1_score\n",
    "        total_cosine_sim += cosine_sim\n",
    "        \n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Context: {context}\\n\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Predicted Answer: {predicted_answer}\")\n",
    "        print(f\"Actual Answer: {actual_answer}\")\n",
    "        print(f\"Score: {prediction['score']:.4f}\")\n",
    "        print(f\"Exact Match: {exact_match}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    avg_exact_match = total_exact_match / num_examples\n",
    "    avg_f1_score = total_f1_score / num_examples\n",
    "    avg_cosine_sim = total_cosine_sim / num_examples\n",
    "    \n",
    "    print(\"Overall Evaluation Results:\")\n",
    "    print(f\"Average Exact Match: {avg_exact_match:.4f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1_score:.4f}\")\n",
    "    print(f\"Average Cosine Similarity: {avg_cosine_sim:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:11:22.615706Z",
     "iopub.status.busy": "2024-12-18T17:11:22.615030Z",
     "iopub.status.idle": "2024-12-18T17:11:27.299420Z",
     "shell.execute_reply": "2024-12-18T17:11:27.298670Z",
     "shell.execute_reply.started": "2024-12-18T17:11:22.615671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming data: 100%|██████████| 700/700 [00:00<00:00, 15715.65it/s]\n",
      "Transforming data: 100%|██████████| 150/150 [00:00<00:00, 15716.85it/s]\n",
      "Transforming data: 100%|██████████| 150/150 [00:00<00:00, 14127.94it/s]\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 5 examples...\n",
      "\n",
      "Example 1:\n",
      "Context: ['1991 ۾، آمريڪي صدر جارج ايڇ ڊبليو بش هائيڪ کي صدارتي ميڊل آف فريڊم سان نوازيو، جيڪو آمريڪا جي ٻن اعليٰ ترين سول ايوارڊن مان هڪ آهي، سڄي زندگي افق کان ٻاهر ڏسڻ لاءِ. هاءِڪ 23 مارچ 1992 تي ”فريبرگ، جرمني“ ۾ وفات ڪئي ۽ 4 اپريل تي کيس ڪيٿولڪ رسم موجب ويانا جي اترئين حصي ۾ نيوسٽيفٽ ام والڊ قبرستان ۾ دفن ڪيو ويو. 2011 ۾، سندس مضمون The Use of Knowledge in Society کي منتخب ڪيو ويو مٿئين 20 مضمونن مان جيڪو آمريڪي اقتصادي جائزو ۾ شايع ٿيو ان جي پهرين 100 سالن دوران.']\n",
      "\n",
      "Question: هيڪ ڪٿي هو جڏهن هو مري ويو؟\n",
      "Predicted Answer: فريبرگ، جرمني\n",
      "Actual Answer: فريبرگ، جرمني\n",
      "Score: 0.1669\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 2:\n",
      "Context: ['UNFPA جو تعلق ”چين“ جي انتظاميا سان زبردستي حملن جي انڪشافن پاران رد ڪيو ويو مختلف يو ايس، برطانيه ۽ گڏيل قومن جي ٽيمن پاران چين ۾ UNFPA جي سرگرمين کي جانچڻ لاءِ موڪليو ويو. خاص طور تي، آمريڪا جي اسٽيٽ ڊپارٽمنٽ جي حقيقت ڳولڻ واري ٽيم ٽن ماڻهن کي سڄي چين ۾ ٻن هفتن جي دوري تي موڪليو ويو. اهو اسٽيٽ ڊپارٽمينٽ ڏانهن هڪ رپورٽ ۾ لکيو آهي ته اهو ڪو ثبوت نه مليو ته UNFPA چين ۾ زبردستي اسقاط حمل يا غير ارادي نسبندي جي پروگرام جي انتظام ۾ مدد ڪئي آهي يا حصو ورتو آهي، جيئن نقادن طرفان الزام لڳايو ويو آهي.']\n",
      "\n",
      "Question: ڪهڙو ملڪ تمام گهٽ اسقاط حمل جو انتظام ڪري رهيو هو؟\n",
      "Predicted Answer: چين\n",
      "Actual Answer: چين\n",
      "Score: 0.1901\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 3:\n",
      "Context: ['سڄي يورپ جي حڪمرانن ۽ شهري حڪومتن يورپ جي علم جي اڃ کي پورو ڪرڻ لاءِ يونيورسٽيون ٺاهڻ شروع ڪيون ۽ اهو يقين ڏياريو ته سماج انهن ادارن مان پيدا ٿيندڙ علمي صلاحيتن مان فائدو حاصل ڪندو. شهري حڪومتن جا شهزادا ۽ اڳواڻن هڪ عالمانه مهارت حاصل ڪرڻ جي امڪاني فائدن کي سمجهي ورتو آهي جيڪي مشڪل مسئلن کي حل ڪرڻ ۽ گهربل مقصد حاصل ڪرڻ جي صلاحيت سان ترقي ڪن ٿا. ”انسانيت“ جو ظهور ان لاءِ ضروري هو ته يونيورسٽين جي ممڪن افاديت کي سمجهڻ ۽ ان سان گڏ قديم يوناني نسخن مان حاصل ڪيل علم ۾ دلچسپي جي بحاليءَ لاءِ.']\n",
      "\n",
      "Question: يورپي نظام جي پيدائش جو ڪهڙو نقشو پيدا ٿيو؟\n",
      "Predicted Answer: انسانيت\n",
      "Actual Answer: انسانيت\n",
      "Score: 0.2713\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 4:\n",
      "Context: ['18 جون، 2009 تي، نيشنل آرڪائيوز يوٽيوب چينل شروع ڪرڻ جو اعلان ڪيو ••مشهور آرڪائيو ٿيل فلمن کي ڏيکارڻ، عوام کي سڄي ملڪ ۾ ايندڙ واقعن بابت آگاهي ڏيڻ••، ۽ نيشنل آرڪائيوز جي نمائش کي ماڻهن تائين پهچايو. 2009 ۾ پڻ، نيشنل آرڪائيوز هڪ فلڪر فوٽو اسٽريم شروع ڪيو ته جيئن ان جي فوٽوگرافڪ هولڊنگ جا حصا عام عوام سان شيئر ڪن. دستاويزن سان گڏ هڪ نئين تدريس ويب سائيٽ 2010 ۾ پريميئر ڪئي وئي ۽ تعليمي ٽيم پاران ترقي ڪئي وئي. ويب سائيٽ 3,000 دستاويزن، تصويرون، ۽ آرڪائيوز جي ذخيري مان رڪارڊنگ جي خصوصيت رکي ٿي. سائيٽ نئين ڪلاس روم جون سرگرميون ۽ سبق ٺاهڻ لاءِ سبق جا منصوبا ۽ اوزار پڻ پيش ڪري ٿي.']\n",
      "\n",
      "Question: يوٽيوب سائيٽ پهريون ڀيرو 2010 ۾ ڇو شروع ڪئي وئي؟\n",
      "Predicted Answer: 18 جون، 2009\n",
      "Actual Answer: مشهور آرڪائيو ٿيل فلمن کي ڏيکارڻ لاء، سڄي ملڪ ۾ ايندڙ واقعن بابت عوام کي آگاهي ڏيڻ\n",
      "Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "Cosine Similarity: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 5:\n",
      "Context: ['ميڪسيڪو سٽي ملڪ جي ڪجهه بهترين خانگي اسپتالن جو گهر آهي؛ اسپتال اينجلس، اسپتال ABC ۽ Médica Sur ڪجهه نالا ڏيڻ لاءِ. نجي شعبي جي ملازمن لاءِ قومي پبلڪ هيلٿ ڪيئر ادارو، IMSS، ميڪسيڪو سٽي ۾ سڀ کان وڏيون سهولتون آهن- جن ۾ نيشنل ميڊيڪل سينٽر ۽ لا رضا ميڊيڪل سينٽر شامل آهن- ۽ ان جي سالياني بجيٽ آهي ”6 بلين پئسو“ کان وڌيڪ. IMSS ۽ ٻيا عوامي صحت جا ادارا، بشمول ISSSTE (پبلڪ سيڪٽر ايمپلائيز سوشل سيڪيورٽي انسٽيٽيوٽ) ۽ قومي صحت واري وزارت (SSA) شهر ۾ وڏيون خاص سهولتون برقرار رکن ٿيون. انهن ۾ شامل آهن نيشنل انسٽيٽيوٽ آف ڪارڊيالوجي، غذائيت، نفسيات، آنڪولوجي، ٻارن جي بيمارين، بحالي، ٻين جي وچ ۾.']\n",
      "\n",
      "Question: IMSS جي بجيٽ ڪيتري آهي؟\n",
      "Predicted Answer: 6 بلين پئسو\n",
      "Actual Answer: 6 بلين پئسو کان وڌيڪ\n",
      "Score: 0.1025\n",
      "Exact Match: 0\n",
      "F1 Score: 0.7500\n",
      "Cosine Similarity: 0.7071\n",
      "--------------------------------------------------------------------------------\n",
      "Overall Evaluation Results:\n",
      "Average Exact Match: 0.6000\n",
      "Average F1 Score: 0.7500\n",
      "Average Cosine Similarity: 0.7414\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "input_csv2 = \"/kaggle/working/test_data.csv\"\n",
    "dataset = load_and_split_data(input_csv2)  \n",
    "display_results_qa_model(tokenizer, model, dataset, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:38:06.130247Z",
     "iopub.status.busy": "2024-12-18T17:38:06.129895Z",
     "iopub.status.idle": "2024-12-18T17:38:06.138861Z",
     "shell.execute_reply": "2024-12-18T17:38:06.137987Z",
     "shell.execute_reply.started": "2024-12-18T17:38:06.130214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_qa_perturbed(dataset,model, context_column, question_column, answer_column):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "    results = []\n",
    "    correct_predictions = 0\n",
    "    total_questions = len(dataset)\n",
    "    total_f1 = 0.0\n",
    "    total_levenshtein = 0.0\n",
    "\n",
    "    f1_scores = []\n",
    "    \n",
    "    true_answers = []\n",
    "    predicted_answers = []\n",
    "\n",
    "    for idx, row in dataset.iterrows():\n",
    "        context = row[context_column]\n",
    "        question = row[question_column]\n",
    "        true_answer = row[answer_column]\n",
    "        \n",
    "        prediction = qa_pipeline({\"context\": context, \"question\": question})\n",
    "        predicted_answer = prediction.get(\"answer\", \"\")\n",
    "\n",
    "        if true_answer.lower().strip() == predicted_answer.lower().strip():\n",
    "            correct_predictions += 1\n",
    "\n",
    "        true_answers.append(true_answer.lower().strip())\n",
    "        predicted_answers.append(predicted_answer.lower().strip())\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"true_answer\": true_answer,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "        })\n",
    "\n",
    "    f1 = f1_score(true_answers, predicted_answers, average='weighted')\n",
    "\n",
    "    accuracy = correct_predictions / total_questions if total_questions > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_questions})\")\n",
    "    print(f\"Average F1 Score (Sklearn): {f1:.2f}\")\n",
    "    \n",
    "    return f1_scores, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:38:10.268092Z",
     "iopub.status.busy": "2024-12-18T17:38:10.267740Z",
     "iopub.status.idle": "2024-12-18T17:39:03.854866Z",
     "shell.execute_reply": "2024-12-18T17:39:03.853995Z",
     "shell.execute_reply.started": "2024-12-18T17:38:10.268060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating altered dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49/2892646513.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  context = row[context_column]\n",
      "/tmp/ipykernel_49/2892646513.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  question = row[question_column]\n",
      "/tmp/ipykernel_49/2892646513.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  true_answer = row[answer_column]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.17% (32/1010)\n",
      "Average F1 Score (Sklearn): 0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/kaggle/input/perturbed-sindhi/pertubated_sindhi_translated.csv'\n",
    "data = pd.read_csv(data_path).dropna()\n",
    "\n",
    "altered_data = data.iloc[:, [2, 3, 4]]  \n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\u0600-\\u06FFa-zA-Z0-9\\s,؟۔!\"\\'()-]', '', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "altered_data.iloc[:, 0] = altered_data.iloc[:, 0].apply(clean_text)  \n",
    "altered_data.iloc[:, 1] = altered_data.iloc[:, 1].apply(clean_text)  \n",
    "altered_data.iloc[:, 2] = altered_data.iloc[:, 2].apply(clean_text)  \n",
    "\n",
    "\n",
    "print(\"Evaluating altered dataset...\")\n",
    "altered_f1_scores, altered_results = evaluate_qa_perturbed(altered_data,model, 0,1, 2)\n",
    "\n",
    "altered_results_df = pd.DataFrame(altered_results)\n",
    "\n",
    "altered_results_df.to_csv(\"altered_results.csv\", index=False, encoding='utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6324537,
     "sourceId": 10229201,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6325018,
     "sourceId": 10229857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6329301,
     "sourceId": 10235826,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6330027,
     "sourceId": 10236753,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6331400,
     "sourceId": 10238451,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0873a071fbaa4f6387efd23e7ac39dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1531e600986d4473a7360e88359d1a46",
       "IPY_MODEL_18403d589308493db9ba377090a34c44",
       "IPY_MODEL_89c3740c9c174fd0b17a28e9765fc199"
      ],
      "layout": "IPY_MODEL_4e6a7b499cc747f289e5207d00e30a3d"
     }
    },
    "0fc4295793354da6a173c6ade75dbbbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1531e600986d4473a7360e88359d1a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e8e9a937974d9f9285cf88af5b0120",
      "placeholder": "​",
      "style": "IPY_MODEL_b9a8e2eecee44423ba75d030f948cf0f",
      "value": "Map: 100%"
     }
    },
    "18403d589308493db9ba377090a34c44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c3d5bee60684097b1769b85055d2ba0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_485bb599b71947e3b4e882d6e2033120",
      "value": 100
     }
    },
    "18aaa42f4a4a4b109b0f58c823ede3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cfd23a98804975bb6dcb25f348946c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c3d5bee60684097b1769b85055d2ba0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3eb4a29511184341ac5c514d1e8738c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e666a8b7ebb14b4aa7589f1a1bc37157",
      "placeholder": "​",
      "style": "IPY_MODEL_b8130811f37a439b95a9b7507145a191",
      "value": "Map: 100%"
     }
    },
    "46eb6063b3754f45996a5f3e84817f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3eb4a29511184341ac5c514d1e8738c1",
       "IPY_MODEL_7e3d0cc15e4e4ea4a4a5e2400ef68b64",
       "IPY_MODEL_fd71120efd6a4c29ac659d43d5cdb8e9"
      ],
      "layout": "IPY_MODEL_f0b344279c7e4cb29304132460ba70a1"
     }
    },
    "485bb599b71947e3b4e882d6e2033120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e6a7b499cc747f289e5207d00e30a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e0e0f1196fc4f3bbed292f0f3de93a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60a8977d11e1469bacb832507022f35a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73e8e9a937974d9f9285cf88af5b0120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e3d0cc15e4e4ea4a4a5e2400ef68b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18aaa42f4a4a4b109b0f58c823ede3e5",
      "max": 900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_60a8977d11e1469bacb832507022f35a",
      "value": 900
     }
    },
    "89c3740c9c174fd0b17a28e9765fc199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20cfd23a98804975bb6dcb25f348946c",
      "placeholder": "​",
      "style": "IPY_MODEL_5e0e0f1196fc4f3bbed292f0f3de93a0",
      "value": " 100/100 [00:00&lt;00:00, 304.21 examples/s]"
     }
    },
    "b8130811f37a439b95a9b7507145a191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9a8e2eecee44423ba75d030f948cf0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e666a8b7ebb14b4aa7589f1a1bc37157": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b344279c7e4cb29304132460ba70a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f59386a1cd414a979006522ad13fdac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd71120efd6a4c29ac659d43d5cdb8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fc4295793354da6a173c6ade75dbbbf",
      "placeholder": "​",
      "style": "IPY_MODEL_f59386a1cd414a979006522ad13fdac4",
      "value": " 900/900 [00:02&lt;00:00, 448.52 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

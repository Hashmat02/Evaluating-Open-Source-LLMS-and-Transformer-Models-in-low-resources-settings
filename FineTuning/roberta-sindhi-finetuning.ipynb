{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-18T16:33:57.525660Z",
     "iopub.status.busy": "2024-12-18T16:33:57.525300Z",
     "iopub.status.idle": "2024-12-18T16:34:07.371060Z",
     "shell.execute_reply": "2024-12-18T16:34:07.369993Z",
     "shell.execute_reply.started": "2024-12-18T16:33:57.525618Z"
    },
    "id": "rIIh2awoCKMJ",
    "outputId": "32a9dde5-319c-43fc-e58a-6a4abaa97332",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets transformers torch\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:07.372949Z",
     "iopub.status.busy": "2024-12-18T16:34:07.372551Z",
     "iopub.status.idle": "2024-12-18T16:34:08.544329Z",
     "shell.execute_reply": "2024-12-18T16:34:08.543348Z",
     "shell.execute_reply.started": "2024-12-18T16:34:07.372897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Train and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Data = \"/kaggle/input/sindhi-qa/cleaned_SQuAD_Sindhi.csv\"\n",
    "data = pd.read_csv(Data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=40)\n",
    "train_data.to_csv(\"/kaggle/working/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"/kaggle/working/test_data.csv\", index=False)\n",
    "print(\"Dataset split complete. Train and test datasets saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:08.546292Z",
     "iopub.status.busy": "2024-12-18T16:34:08.546029Z",
     "iopub.status.idle": "2024-12-18T16:34:26.888919Z",
     "shell.execute_reply": "2024-12-18T16:34:26.888195Z",
     "shell.execute_reply.started": "2024-12-18T16:34:08.546264Z"
    },
    "id": "zGepLnupWOEj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForQuestionAnswering, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.890334Z",
     "iopub.status.busy": "2024-12-18T16:34:26.889850Z",
     "iopub.status.idle": "2024-12-18T16:34:26.898433Z",
     "shell.execute_reply": "2024-12-18T16:34:26.897459Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.890307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_split_data(\n",
    "    input_csv, \n",
    "    train_ratio=0.7, \n",
    "    test_ratio=0.15, \n",
    "    random_seed=42\n",
    "):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    total_samples = len(df)\n",
    "    train_end = int(total_samples * train_ratio)\n",
    "    val_end = train_end + int(total_samples * test_ratio)\n",
    "    \n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "    \n",
    "    def transform_subset(subset_df):\n",
    "        records = []\n",
    "        for _, row in tqdm(subset_df.iterrows(), total=len(subset_df), \n",
    "                            desc=\"Transforming data\"):\n",
    "            context = ' '.join(row['context']) if isinstance(row['context'], list) else row['context']\n",
    "            \n",
    "            answer_start = context.find(row['answer']) \\\n",
    "                if not row['is_impossible'] else -1\n",
    "            \n",
    "            record = {\n",
    "                \"id\": row.get('id', ''),\n",
    "                \"title\": row.get('title', ''),\n",
    "                \"context\": context,\n",
    "                \"question\": row['question'],\n",
    "                \"answer\": row['answer'],\n",
    "                \"answer_start\": answer_start,\n",
    "                \"is_impossible\": row['is_impossible']\n",
    "            }\n",
    "            records.append(record)\n",
    "        return records\n",
    "    \n",
    "    train_records = transform_subset(train_df)\n",
    "    val_records = transform_subset(val_df)\n",
    "    test_records = transform_subset(test_df)\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(pd.DataFrame(train_records))\n",
    "    val_dataset = Dataset.from_pandas(pd.DataFrame(val_records))\n",
    "    test_dataset = Dataset.from_pandas(pd.DataFrame(test_records))\n",
    "    \n",
    "    return DatasetDict({\n",
    "        \"train\": train_dataset, \n",
    "        \"validation\": val_dataset, \n",
    "        \"test\": test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.899864Z",
     "iopub.status.busy": "2024-12-18T16:34:26.899611Z",
     "iopub.status.idle": "2024-12-18T16:34:26.923722Z",
     "shell.execute_reply": "2024-12-18T16:34:26.923020Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.899838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(tokenizer, examples, max_length=384, stride=128):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    answer_starts = examples[\"answer_start\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer_starts[sample_idx]\n",
    "        end_char = answer_starts[sample_idx] + len(answer)\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "        \n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            \n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:26.925036Z",
     "iopub.status.busy": "2024-12-18T16:34:26.924798Z",
     "iopub.status.idle": "2024-12-18T16:34:26.938860Z",
     "shell.execute_reply": "2024-12-18T16:34:26.938142Z",
     "shell.execute_reply.started": "2024-12-18T16:34:26.925012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_qa_model(\n",
    "    data, \n",
    "    model_name=\"roberta-base\", \n",
    "    num_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    batch_size=32\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    processed_data = data.map(\n",
    "        lambda x: preprocess_function(tokenizer, x), \n",
    "        batched=True, \n",
    "        remove_columns=data[\"train\"].column_names\n",
    "    )\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,  \n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_data[\"train\"],\n",
    "        eval_dataset=processed_data[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    model.save_pretrained(\"./fine_tuned_model\")\n",
    "    tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "    try:\n",
    "        shutil.make_archive(\"./fine_tuned_model_archive\", 'zip', \"./fine_tuned_model\")\n",
    "        print(f\"Model saved and zipped to ./fine_tuned_model_archive.zip\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating zip archive: {e}\")\n",
    "    \n",
    "    return trainer, tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:34:55.031620Z",
     "iopub.status.busy": "2024-12-18T16:34:55.031034Z",
     "iopub.status.idle": "2024-12-18T17:09:53.775612Z",
     "shell.execute_reply": "2024-12-18T17:09:53.774715Z",
     "shell.execute_reply.started": "2024-12-18T16:34:55.031585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2800/2800 [00:00<00:00, 16677.63it/s]\n",
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 17050.94it/s]\n",
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 16459.87it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbeb8e7b99f40d0b1ea1e9859a979b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8699690820f045b89dc92a725195695d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac494abce694cb5ba4d552e51916550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259f1998df974dbd86efbf9893d26454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e22bb828ecb4e839bd1f2cb31daef72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7062c7f30594c459b8dcdfb356f4042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefb26d2c92f412898e0eb5c1f74ae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ba48c13a534e80914e6819564d99c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3f8061b8254b44965566d87c573ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_49/612374700.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241218_163518-g0v6al28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/mirzaarham796-lums/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mirzaarham796-lums/huggingface' target=\"_blank\">https://wandb.ai/mirzaarham796-lums/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28' target=\"_blank\">https://wandb.ai/mirzaarham796-lums/huggingface/runs/g0v6al28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 33:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.336278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.322926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.321187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.313713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.311321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved and zipped to ./fine_tuned_model_archive.zip\n"
     ]
    }
   ],
   "source": [
    "input_csv = \"/kaggle/working/train_data.csv\"\n",
    "dataset = load_and_split_data(input_csv)\n",
    "trainer, tokenizer, model = train_qa_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:11:17.864379Z",
     "iopub.status.busy": "2024-12-18T17:11:17.863560Z",
     "iopub.status.idle": "2024-12-18T17:11:17.933891Z",
     "shell.execute_reply": "2024-12-18T17:11:17.933227Z",
     "shell.execute_reply.started": "2024-12-18T17:11:17.864346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "def calculate_exact_match(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)  \n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)  \n",
    "    return 1 if predicted_answer.strip().lower() == actual_answer.strip().lower() else 0\n",
    "\n",
    "def calculate_f1_score(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)\n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)\n",
    "    \n",
    "    pred_tokens = set(predicted_answer.strip().lower().split())\n",
    "    actual_tokens = set(actual_answer.strip().lower().split())\n",
    "    precision = len(pred_tokens & actual_tokens) / len(pred_tokens) if pred_tokens else 0\n",
    "    recall = len(pred_tokens & actual_tokens) / len(actual_tokens) if actual_tokens else 0\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "def calculate_cosine_similarity(predicted_answer, actual_answer):\n",
    "    if isinstance(predicted_answer, list):\n",
    "        predicted_answer = \" \".join(predicted_answer)\n",
    "    if isinstance(actual_answer, list):\n",
    "        actual_answer = \" \".join(actual_answer)\n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform([predicted_answer, actual_answer])\n",
    "    cos_sim = cosine_similarity(vectorizer[0:1], vectorizer[1:2])\n",
    "    return cos_sim[0][0]\n",
    "\n",
    "def display_results_qa_model(tokenizer, model, dataset, num_examples=5):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    examples = dataset[\"validation\"].select(range(num_examples))\n",
    "    \n",
    "    total_exact_match = 0\n",
    "    total_f1_score = 0\n",
    "    total_cosine_sim = 0\n",
    "    \n",
    "    print(\"Evaluating on 5 examples...\\n\")\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        actual_answer = example['answer'] \n",
    "        prediction = qa_pipeline(question=question, context=context)\n",
    "        predicted_answer = prediction['answer']\n",
    "        predicted_answer = predicted_answer.replace(\"â€¢â€¢\", \"\")\n",
    "\n",
    "        exact_match = calculate_exact_match(predicted_answer, actual_answer)\n",
    "        f1_score = calculate_f1_score(predicted_answer, actual_answer)\n",
    "        cosine_sim = calculate_cosine_similarity(predicted_answer, actual_answer)\n",
    "        \n",
    "        total_exact_match += exact_match\n",
    "        total_f1_score += f1_score\n",
    "        total_cosine_sim += cosine_sim\n",
    "        \n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Context: {context}\\n\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Predicted Answer: {predicted_answer}\")\n",
    "        print(f\"Actual Answer: {actual_answer}\")\n",
    "        print(f\"Score: {prediction['score']:.4f}\")\n",
    "        print(f\"Exact Match: {exact_match}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    avg_exact_match = total_exact_match / num_examples\n",
    "    avg_f1_score = total_f1_score / num_examples\n",
    "    avg_cosine_sim = total_cosine_sim / num_examples\n",
    "    \n",
    "    print(\"Overall Evaluation Results:\")\n",
    "    print(f\"Average Exact Match: {avg_exact_match:.4f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1_score:.4f}\")\n",
    "    print(f\"Average Cosine Similarity: {avg_cosine_sim:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:11:22.615706Z",
     "iopub.status.busy": "2024-12-18T17:11:22.615030Z",
     "iopub.status.idle": "2024-12-18T17:11:27.299420Z",
     "shell.execute_reply": "2024-12-18T17:11:27.298670Z",
     "shell.execute_reply.started": "2024-12-18T17:11:22.615671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [00:00<00:00, 15715.65it/s]\n",
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 15716.85it/s]\n",
      "Transforming data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 14127.94it/s]\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 5 examples...\n",
      "\n",
      "Example 1:\n",
      "Context: ['1991 Û¾ØŒ Ø¢Ù…Ø±ÙŠÚªÙŠ ØµØ¯Ø± Ø¬Ø§Ø±Ø¬ Ø§ÙŠÚ‡ ÚŠØ¨Ù„ÙŠÙˆ Ø¨Ø´ Ù‡Ø§Ø¦ÙŠÚª Ú©ÙŠ ØµØ¯Ø§Ø±ØªÙŠ Ù…ÙŠÚŠÙ„ Ø¢Ù ÙØ±ÙŠÚŠÙ… Ø³Ø§Ù† Ù†ÙˆØ§Ø²ÙŠÙˆØŒ Ø¬ÙŠÚªÙˆ Ø¢Ù…Ø±ÙŠÚªØ§ Ø¬ÙŠ Ù»Ù† Ø§Ø¹Ù„ÙŠÙ° ØªØ±ÙŠÙ† Ø³ÙˆÙ„ Ø§ÙŠÙˆØ§Ø±ÚŠÙ† Ù…Ø§Ù† Ù‡Úª Ø¢Ù‡ÙŠØŒ Ø³Ú„ÙŠ Ø²Ù†Ø¯Ú¯ÙŠ Ø§ÙÙ‚ Ú©Ø§Ù† Ù»Ø§Ù‡Ø± ÚØ³Ú» Ù„Ø§Ø¡Ù. Ù‡Ø§Ø¡ÙÚª 23 Ù…Ø§Ø±Ú† 1992 ØªÙŠ â€ÙØ±ÙŠØ¨Ø±Ú¯ØŒ Ø¬Ø±Ù…Ù†ÙŠâ€œ Û¾ ÙˆÙØ§Øª ÚªØ¦ÙŠ Û½ 4 Ø§Ù¾Ø±ÙŠÙ„ ØªÙŠ Ú©ÙŠØ³ ÚªÙŠÙ¿ÙˆÙ„Úª Ø±Ø³Ù… Ù…ÙˆØ¬Ø¨ ÙˆÙŠØ§Ù†Ø§ Ø¬ÙŠ Ø§ØªØ±Ø¦ÙŠÙ† Ø­ØµÙŠ Û¾ Ù†ÙŠÙˆØ³Ù½ÙŠÙÙ½ Ø§Ù… ÙˆØ§Ù„ÚŠ Ù‚Ø¨Ø±Ø³ØªØ§Ù† Û¾ Ø¯ÙÙ† ÚªÙŠÙˆ ÙˆÙŠÙˆ. 2011 Û¾ØŒ Ø³Ù†Ø¯Ø³ Ù…Ø¶Ù…ÙˆÙ† The Use of Knowledge in Society Ú©ÙŠ Ù…Ù†ØªØ®Ø¨ ÚªÙŠÙˆ ÙˆÙŠÙˆ Ù…Ù¿Ø¦ÙŠÙ† 20 Ù…Ø¶Ù…ÙˆÙ†Ù† Ù…Ø§Ù† Ø¬ÙŠÚªÙˆ Ø¢Ù…Ø±ÙŠÚªÙŠ Ø§Ù‚ØªØµØ§Ø¯ÙŠ Ø¬Ø§Ø¦Ø²Ùˆ Û¾ Ø´Ø§ÙŠØ¹ Ù¿ÙŠÙˆ Ø§Ù† Ø¬ÙŠ Ù¾Ù‡Ø±ÙŠÙ† 100 Ø³Ø§Ù„Ù† Ø¯ÙˆØ±Ø§Ù†.']\n",
      "\n",
      "Question: Ù‡ÙŠÚª ÚªÙ¿ÙŠ Ù‡Ùˆ Ø¬ÚÙ‡Ù† Ù‡Ùˆ Ù…Ø±ÙŠ ÙˆÙŠÙˆØŸ\n",
      "Predicted Answer: ÙØ±ÙŠØ¨Ø±Ú¯ØŒ Ø¬Ø±Ù…Ù†ÙŠ\n",
      "Actual Answer: ÙØ±ÙŠØ¨Ø±Ú¯ØŒ Ø¬Ø±Ù…Ù†ÙŠ\n",
      "Score: 0.1669\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 2:\n",
      "Context: ['UNFPA Ø¬Ùˆ ØªØ¹Ù„Ù‚ â€Ú†ÙŠÙ†â€œ Ø¬ÙŠ Ø§Ù†ØªØ¸Ø§Ù…ÙŠØ§ Ø³Ø§Ù† Ø²Ø¨Ø±Ø¯Ø³ØªÙŠ Ø­Ù…Ù„Ù† Ø¬ÙŠ Ø§Ù†ÚªØ´Ø§ÙÙ† Ù¾Ø§Ø±Ø§Ù† Ø±Ø¯ ÚªÙŠÙˆ ÙˆÙŠÙˆ Ù…Ø®ØªÙ„Ù ÙŠÙˆ Ø§ÙŠØ³ØŒ Ø¨Ø±Ø·Ø§Ù†ÙŠÙ‡ Û½ Ú¯ÚÙŠÙ„ Ù‚ÙˆÙ…Ù† Ø¬ÙŠ Ù½ÙŠÙ…Ù† Ù¾Ø§Ø±Ø§Ù† Ú†ÙŠÙ† Û¾ UNFPA Ø¬ÙŠ Ø³Ø±Ú¯Ø±Ù…ÙŠÙ† Ú©ÙŠ Ø¬Ø§Ù†Ú†Ú» Ù„Ø§Ø¡Ù Ù…ÙˆÚªÙ„ÙŠÙˆ ÙˆÙŠÙˆ. Ø®Ø§Øµ Ø·ÙˆØ± ØªÙŠØŒ Ø¢Ù…Ø±ÙŠÚªØ§ Ø¬ÙŠ Ø§Ø³Ù½ÙŠÙ½ ÚŠÙ¾Ø§Ø±Ù½Ù…Ù†Ù½ Ø¬ÙŠ Ø­Ù‚ÙŠÙ‚Øª Ú³ÙˆÙ„Ú» ÙˆØ§Ø±ÙŠ Ù½ÙŠÙ… Ù½Ù† Ù…Ø§Ú»Ù‡Ù† Ú©ÙŠ Ø³Ú„ÙŠ Ú†ÙŠÙ† Û¾ Ù»Ù† Ù‡ÙØªÙ† Ø¬ÙŠ Ø¯ÙˆØ±ÙŠ ØªÙŠ Ù…ÙˆÚªÙ„ÙŠÙˆ ÙˆÙŠÙˆ. Ø§Ù‡Ùˆ Ø§Ø³Ù½ÙŠÙ½ ÚŠÙ¾Ø§Ø±Ù½Ù…ÙŠÙ†Ù½ ÚØ§Ù†Ù‡Ù† Ù‡Úª Ø±Ù¾ÙˆØ±Ù½ Û¾ Ù„Ú©ÙŠÙˆ Ø¢Ù‡ÙŠ ØªÙ‡ Ø§Ù‡Ùˆ ÚªÙˆ Ø«Ø¨ÙˆØª Ù†Ù‡ Ù…Ù„ÙŠÙˆ ØªÙ‡ UNFPA Ú†ÙŠÙ† Û¾ Ø²Ø¨Ø±Ø¯Ø³ØªÙŠ Ø§Ø³Ù‚Ø§Ø· Ø­Ù…Ù„ ÙŠØ§ ØºÙŠØ± Ø§Ø±Ø§Ø¯ÙŠ Ù†Ø³Ø¨Ù†Ø¯ÙŠ Ø¬ÙŠ Ù¾Ø±ÙˆÚ¯Ø±Ø§Ù… Ø¬ÙŠ Ø§Ù†ØªØ¸Ø§Ù… Û¾ Ù…Ø¯Ø¯ ÚªØ¦ÙŠ Ø¢Ù‡ÙŠ ÙŠØ§ Ø­ØµÙˆ ÙˆØ±ØªÙˆ Ø¢Ù‡ÙŠØŒ Ø¬ÙŠØ¦Ù† Ù†Ù‚Ø§Ø¯Ù† Ø·Ø±ÙØ§Ù† Ø§Ù„Ø²Ø§Ù… Ù„Ú³Ø§ÙŠÙˆ ÙˆÙŠÙˆ Ø¢Ù‡ÙŠ.']\n",
      "\n",
      "Question: ÚªÙ‡Ú™Ùˆ Ù…Ù„Úª ØªÙ…Ø§Ù… Ú¯Ù‡Ù½ Ø§Ø³Ù‚Ø§Ø· Ø­Ù…Ù„ Ø¬Ùˆ Ø§Ù†ØªØ¸Ø§Ù… ÚªØ±ÙŠ Ø±Ù‡ÙŠÙˆ Ù‡ÙˆØŸ\n",
      "Predicted Answer: Ú†ÙŠÙ†\n",
      "Actual Answer: Ú†ÙŠÙ†\n",
      "Score: 0.1901\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 3:\n",
      "Context: ['Ø³Ú„ÙŠ ÙŠÙˆØ±Ù¾ Ø¬ÙŠ Ø­ÚªÙ…Ø±Ø§Ù†Ù† Û½ Ø´Ù‡Ø±ÙŠ Ø­ÚªÙˆÙ…ØªÙ† ÙŠÙˆØ±Ù¾ Ø¬ÙŠ Ø¹Ù„Ù… Ø¬ÙŠ Ø§Úƒ Ú©ÙŠ Ù¾ÙˆØ±Ùˆ ÚªØ±Ú» Ù„Ø§Ø¡Ù ÙŠÙˆÙ†ÙŠÙˆØ±Ø³Ù½ÙŠÙˆÙ† ÙºØ§Ù‡Ú» Ø´Ø±ÙˆØ¹ ÚªÙŠÙˆÙ† Û½ Ø§Ù‡Ùˆ ÙŠÙ‚ÙŠÙ† ÚÙŠØ§Ø±ÙŠÙˆ ØªÙ‡ Ø³Ù…Ø§Ø¬ Ø§Ù†Ù‡Ù† Ø§Ø¯Ø§Ø±Ù† Ù…Ø§Ù† Ù¾ÙŠØ¯Ø§ Ù¿ÙŠÙ†Ø¯Ú™ Ø¹Ù„Ù…ÙŠ ØµÙ„Ø§Ø­ÙŠØªÙ† Ù…Ø§Ù† ÙØ§Ø¦Ø¯Ùˆ Ø­Ø§ØµÙ„ ÚªÙ†Ø¯Ùˆ. Ø´Ù‡Ø±ÙŠ Ø­ÚªÙˆÙ…ØªÙ† Ø¬Ø§ Ø´Ù‡Ø²Ø§Ø¯Ø§ Û½ Ø§Ú³ÙˆØ§Ú»Ù† Ù‡Úª Ø¹Ø§Ù„Ù…Ø§Ù†Ù‡ Ù…Ù‡Ø§Ø±Øª Ø­Ø§ØµÙ„ ÚªØ±Ú» Ø¬ÙŠ Ø§Ù…ÚªØ§Ù†ÙŠ ÙØ§Ø¦Ø¯Ù† Ú©ÙŠ Ø³Ù…Ø¬Ù‡ÙŠ ÙˆØ±ØªÙˆ Ø¢Ù‡ÙŠ Ø¬ÙŠÚªÙŠ Ù…Ø´ÚªÙ„ Ù…Ø³Ø¦Ù„Ù† Ú©ÙŠ Ø­Ù„ ÚªØ±Ú» Û½ Ú¯Ù‡Ø±Ø¨Ù„ Ù…Ù‚ØµØ¯ Ø­Ø§ØµÙ„ ÚªØ±Ú» Ø¬ÙŠ ØµÙ„Ø§Ø­ÙŠØª Ø³Ø§Ù† ØªØ±Ù‚ÙŠ ÚªÙ† Ù¿Ø§. â€Ø§Ù†Ø³Ø§Ù†ÙŠØªâ€œ Ø¬Ùˆ Ø¸Ù‡ÙˆØ± Ø§Ù† Ù„Ø§Ø¡Ù Ø¶Ø±ÙˆØ±ÙŠ Ù‡Ùˆ ØªÙ‡ ÙŠÙˆÙ†ÙŠÙˆØ±Ø³Ù½ÙŠÙ† Ø¬ÙŠ Ù…Ù…ÚªÙ† Ø§ÙØ§Ø¯ÙŠØª Ú©ÙŠ Ø³Ù…Ø¬Ù‡Ú» Û½ Ø§Ù† Ø³Ø§Ù† Ú¯Ú Ù‚Ø¯ÙŠÙ… ÙŠÙˆÙ†Ø§Ù†ÙŠ Ù†Ø³Ø®Ù† Ù…Ø§Ù† Ø­Ø§ØµÙ„ ÚªÙŠÙ„ Ø¹Ù„Ù… Û¾ Ø¯Ù„Ú†Ø³Ù¾ÙŠ Ø¬ÙŠ Ø¨Ø­Ø§Ù„ÙŠØ¡ÙŽ Ù„Ø§Ø¡Ù.']\n",
      "\n",
      "Question: ÙŠÙˆØ±Ù¾ÙŠ Ù†Ø¸Ø§Ù… Ø¬ÙŠ Ù¾ÙŠØ¯Ø§Ø¦Ø´ Ø¬Ùˆ ÚªÙ‡Ú™Ùˆ Ù†Ù‚Ø´Ùˆ Ù¾ÙŠØ¯Ø§ Ù¿ÙŠÙˆØŸ\n",
      "Predicted Answer: Ø§Ù†Ø³Ø§Ù†ÙŠØª\n",
      "Actual Answer: Ø§Ù†Ø³Ø§Ù†ÙŠØª\n",
      "Score: 0.2713\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "Cosine Similarity: 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 4:\n",
      "Context: ['18 Ø¬ÙˆÙ†ØŒ 2009 ØªÙŠØŒ Ù†ÙŠØ´Ù†Ù„ Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆØ² ÙŠÙˆÙ½ÙŠÙˆØ¨ Ú†ÙŠÙ†Ù„ Ø´Ø±ÙˆØ¹ ÚªØ±Ú» Ø¬Ùˆ Ø§Ø¹Ù„Ø§Ù† ÚªÙŠÙˆ â€¢â€¢Ù…Ø´Ù‡ÙˆØ± Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆ Ù¿ÙŠÙ„ ÙÙ„Ù…Ù† Ú©ÙŠ ÚÙŠÚ©Ø§Ø±Ú»ØŒ Ø¹ÙˆØ§Ù… Ú©ÙŠ Ø³Ú„ÙŠ Ù…Ù„Úª Û¾ Ø§ÙŠÙ†Ø¯Ú™ ÙˆØ§Ù‚Ø¹Ù† Ø¨Ø§Ø¨Øª Ø¢Ú¯Ø§Ù‡ÙŠ ÚÙŠÚ»â€¢â€¢ØŒ Û½ Ù†ÙŠØ´Ù†Ù„ Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆØ² Ø¬ÙŠ Ù†Ù…Ø§Ø¦Ø´ Ú©ÙŠ Ù…Ø§Ú»Ù‡Ù† ØªØ§Ø¦ÙŠÙ† Ù¾Ù‡Ú†Ø§ÙŠÙˆ. 2009 Û¾ Ù¾Ú»ØŒ Ù†ÙŠØ´Ù†Ù„ Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆØ² Ù‡Úª ÙÙ„ÚªØ± ÙÙˆÙ½Ùˆ Ø§Ø³Ù½Ø±ÙŠÙ… Ø´Ø±ÙˆØ¹ ÚªÙŠÙˆ ØªÙ‡ Ø¬ÙŠØ¦Ù† Ø§Ù† Ø¬ÙŠ ÙÙˆÙ½ÙˆÚ¯Ø±Ø§ÙÚª Ù‡ÙˆÙ„ÚŠÙ†Ú¯ Ø¬Ø§ Ø­ØµØ§ Ø¹Ø§Ù… Ø¹ÙˆØ§Ù… Ø³Ø§Ù† Ø´ÙŠØ¦Ø± ÚªÙ†. Ø¯Ø³ØªØ§ÙˆÙŠØ²Ù† Ø³Ø§Ù† Ú¯Ú Ù‡Úª Ù†Ø¦ÙŠÙ† ØªØ¯Ø±ÙŠØ³ ÙˆÙŠØ¨ Ø³Ø§Ø¦ÙŠÙ½ 2010 Û¾ Ù¾Ø±ÙŠÙ…ÙŠØ¦Ø± ÚªØ¦ÙŠ ÙˆØ¦ÙŠ Û½ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù½ÙŠÙ… Ù¾Ø§Ø±Ø§Ù† ØªØ±Ù‚ÙŠ ÚªØ¦ÙŠ ÙˆØ¦ÙŠ. ÙˆÙŠØ¨ Ø³Ø§Ø¦ÙŠÙ½ 3,000 Ø¯Ø³ØªØ§ÙˆÙŠØ²Ù†ØŒ ØªØµÙˆÙŠØ±ÙˆÙ†ØŒ Û½ Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆØ² Ø¬ÙŠ Ø°Ø®ÙŠØ±ÙŠ Ù…Ø§Ù† Ø±ÚªØ§Ø±ÚŠÙ†Ú¯ Ø¬ÙŠ Ø®ØµÙˆØµÙŠØª Ø±Ú©ÙŠ Ù¿ÙŠ. Ø³Ø§Ø¦ÙŠÙ½ Ù†Ø¦ÙŠÙ† ÚªÙ„Ø§Ø³ Ø±ÙˆÙ… Ø¬ÙˆÙ† Ø³Ø±Ú¯Ø±Ù…ÙŠÙˆÙ† Û½ Ø³Ø¨Ù‚ ÙºØ§Ù‡Ú» Ù„Ø§Ø¡Ù Ø³Ø¨Ù‚ Ø¬Ø§ Ù…Ù†ØµÙˆØ¨Ø§ Û½ Ø§ÙˆØ²Ø§Ø± Ù¾Ú» Ù¾ÙŠØ´ ÚªØ±ÙŠ Ù¿ÙŠ.']\n",
      "\n",
      "Question: ÙŠÙˆÙ½ÙŠÙˆØ¨ Ø³Ø§Ø¦ÙŠÙ½ Ù¾Ù‡Ø±ÙŠÙˆÙ† Ú€ÙŠØ±Ùˆ 2010 Û¾ Ú‡Ùˆ Ø´Ø±ÙˆØ¹ ÚªØ¦ÙŠ ÙˆØ¦ÙŠØŸ\n",
      "Predicted Answer: 18 Ø¬ÙˆÙ†ØŒ 2009\n",
      "Actual Answer: Ù…Ø´Ù‡ÙˆØ± Ø¢Ø±ÚªØ§Ø¦ÙŠÙˆ Ù¿ÙŠÙ„ ÙÙ„Ù…Ù† Ú©ÙŠ ÚÙŠÚ©Ø§Ø±Ú» Ù„Ø§Ø¡ØŒ Ø³Ú„ÙŠ Ù…Ù„Úª Û¾ Ø§ÙŠÙ†Ø¯Ú™ ÙˆØ§Ù‚Ø¹Ù† Ø¨Ø§Ø¨Øª Ø¹ÙˆØ§Ù… Ú©ÙŠ Ø¢Ú¯Ø§Ù‡ÙŠ ÚÙŠÚ»\n",
      "Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "Cosine Similarity: 0.0000\n",
      "--------------------------------------------------------------------------------\n",
      "Example 5:\n",
      "Context: ['Ù…ÙŠÚªØ³ÙŠÚªÙˆ Ø³Ù½ÙŠ Ù…Ù„Úª Ø¬ÙŠ ÚªØ¬Ù‡Ù‡ Ø¨Ù‡ØªØ±ÙŠÙ† Ø®Ø§Ù†Ú¯ÙŠ Ø§Ø³Ù¾ØªØ§Ù„Ù† Ø¬Ùˆ Ú¯Ù‡Ø± Ø¢Ù‡ÙŠØ› Ø§Ø³Ù¾ØªØ§Ù„ Ø§ÙŠÙ†Ø¬Ù„Ø³ØŒ Ø§Ø³Ù¾ØªØ§Ù„ ABC Û½ MÃ©dica Sur ÚªØ¬Ù‡Ù‡ Ù†Ø§Ù„Ø§ ÚÙŠÚ» Ù„Ø§Ø¡Ù. Ù†Ø¬ÙŠ Ø´Ø¹Ø¨ÙŠ Ø¬ÙŠ Ù…Ù„Ø§Ø²Ù…Ù† Ù„Ø§Ø¡Ù Ù‚ÙˆÙ…ÙŠ Ù¾Ø¨Ù„Úª Ù‡ÙŠÙ„Ù¿ ÚªÙŠØ¦Ø± Ø§Ø¯Ø§Ø±ÙˆØŒ IMSSØŒ Ù…ÙŠÚªØ³ÙŠÚªÙˆ Ø³Ù½ÙŠ Û¾ Ø³Ú€ Ú©Ø§Ù† ÙˆÚÙŠÙˆÙ† Ø³Ù‡ÙˆÙ„ØªÙˆÙ† Ø¢Ù‡Ù†- Ø¬Ù† Û¾ Ù†ÙŠØ´Ù†Ù„ Ù…ÙŠÚŠÙŠÚªÙ„ Ø³ÙŠÙ†Ù½Ø± Û½ Ù„Ø§ Ø±Ø¶Ø§ Ù…ÙŠÚŠÙŠÚªÙ„ Ø³ÙŠÙ†Ù½Ø± Ø´Ø§Ù…Ù„ Ø¢Ù‡Ù†- Û½ Ø§Ù† Ø¬ÙŠ Ø³Ø§Ù„ÙŠØ§Ù†ÙŠ Ø¨Ø¬ÙŠÙ½ Ø¢Ù‡ÙŠ â€6 Ø¨Ù„ÙŠÙ† Ù¾Ø¦Ø³Ùˆâ€œ Ú©Ø§Ù† ÙˆÚŒÙŠÚª. IMSS Û½ Ù»ÙŠØ§ Ø¹ÙˆØ§Ù…ÙŠ ØµØ­Øª Ø¬Ø§ Ø§Ø¯Ø§Ø±Ø§ØŒ Ø¨Ø´Ù…ÙˆÙ„ ISSSTE (Ù¾Ø¨Ù„Úª Ø³ÙŠÚªÙ½Ø± Ø§ÙŠÙ…Ù¾Ù„Ø§Ø¦ÙŠØ² Ø³ÙˆØ´Ù„ Ø³ÙŠÚªÙŠÙˆØ±Ù½ÙŠ Ø§Ù†Ø³Ù½ÙŠÙ½ÙŠÙˆÙ½) Û½ Ù‚ÙˆÙ…ÙŠ ØµØ­Øª ÙˆØ§Ø±ÙŠ ÙˆØ²Ø§Ø±Øª (SSA) Ø´Ù‡Ø± Û¾ ÙˆÚÙŠÙˆÙ† Ø®Ø§Øµ Ø³Ù‡ÙˆÙ„ØªÙˆÙ† Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ù† Ù¿ÙŠÙˆÙ†. Ø§Ù†Ù‡Ù† Û¾ Ø´Ø§Ù…Ù„ Ø¢Ù‡Ù† Ù†ÙŠØ´Ù†Ù„ Ø§Ù†Ø³Ù½ÙŠÙ½ÙŠÙˆÙ½ Ø¢Ù ÚªØ§Ø±ÚŠÙŠØ§Ù„ÙˆØ¬ÙŠØŒ ØºØ°Ø§Ø¦ÙŠØªØŒ Ù†ÙØ³ÙŠØ§ØªØŒ Ø¢Ù†ÚªÙˆÙ„ÙˆØ¬ÙŠØŒ Ù»Ø§Ø±Ù† Ø¬ÙŠ Ø¨ÙŠÙ…Ø§Ø±ÙŠÙ†ØŒ Ø¨Ø­Ø§Ù„ÙŠØŒ Ù»ÙŠÙ† Ø¬ÙŠ ÙˆÚ† Û¾.']\n",
      "\n",
      "Question: IMSS Ø¬ÙŠ Ø¨Ø¬ÙŠÙ½ ÚªÙŠØªØ±ÙŠ Ø¢Ù‡ÙŠØŸ\n",
      "Predicted Answer: 6 Ø¨Ù„ÙŠÙ† Ù¾Ø¦Ø³Ùˆ\n",
      "Actual Answer: 6 Ø¨Ù„ÙŠÙ† Ù¾Ø¦Ø³Ùˆ Ú©Ø§Ù† ÙˆÚŒÙŠÚª\n",
      "Score: 0.1025\n",
      "Exact Match: 0\n",
      "F1 Score: 0.7500\n",
      "Cosine Similarity: 0.7071\n",
      "--------------------------------------------------------------------------------\n",
      "Overall Evaluation Results:\n",
      "Average Exact Match: 0.6000\n",
      "Average F1 Score: 0.7500\n",
      "Average Cosine Similarity: 0.7414\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "input_csv2 = \"/kaggle/working/test_data.csv\"\n",
    "dataset = load_and_split_data(input_csv2)  \n",
    "display_results_qa_model(tokenizer, model, dataset, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:38:06.130247Z",
     "iopub.status.busy": "2024-12-18T17:38:06.129895Z",
     "iopub.status.idle": "2024-12-18T17:38:06.138861Z",
     "shell.execute_reply": "2024-12-18T17:38:06.137987Z",
     "shell.execute_reply.started": "2024-12-18T17:38:06.130214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_qa_perturbed(dataset,model, context_column, question_column, answer_column):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "    results = []\n",
    "    correct_predictions = 0\n",
    "    total_questions = len(dataset)\n",
    "    total_f1 = 0.0\n",
    "    total_levenshtein = 0.0\n",
    "\n",
    "    f1_scores = []\n",
    "    \n",
    "    true_answers = []\n",
    "    predicted_answers = []\n",
    "\n",
    "    for idx, row in dataset.iterrows():\n",
    "        context = row[context_column]\n",
    "        question = row[question_column]\n",
    "        true_answer = row[answer_column]\n",
    "        \n",
    "        prediction = qa_pipeline({\"context\": context, \"question\": question})\n",
    "        predicted_answer = prediction.get(\"answer\", \"\")\n",
    "\n",
    "        if true_answer.lower().strip() == predicted_answer.lower().strip():\n",
    "            correct_predictions += 1\n",
    "\n",
    "        true_answers.append(true_answer.lower().strip())\n",
    "        predicted_answers.append(predicted_answer.lower().strip())\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"true_answer\": true_answer,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "        })\n",
    "\n",
    "    f1 = f1_score(true_answers, predicted_answers, average='weighted')\n",
    "\n",
    "    accuracy = correct_predictions / total_questions if total_questions > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_questions})\")\n",
    "    print(f\"Average F1 Score (Sklearn): {f1:.2f}\")\n",
    "    \n",
    "    return f1_scores, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:38:10.268092Z",
     "iopub.status.busy": "2024-12-18T17:38:10.267740Z",
     "iopub.status.idle": "2024-12-18T17:39:03.854866Z",
     "shell.execute_reply": "2024-12-18T17:39:03.853995Z",
     "shell.execute_reply.started": "2024-12-18T17:38:10.268060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating altered dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49/2892646513.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  context = row[context_column]\n",
      "/tmp/ipykernel_49/2892646513.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  question = row[question_column]\n",
      "/tmp/ipykernel_49/2892646513.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  true_answer = row[answer_column]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.17% (32/1010)\n",
      "Average F1 Score (Sklearn): 0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/kaggle/input/perturbed-sindhi/pertubated_sindhi_translated.csv'\n",
    "data = pd.read_csv(data_path).dropna()\n",
    "\n",
    "altered_data = data.iloc[:, [2, 3, 4]]  \n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\u0600-\\u06FFa-zA-Z0-9\\s,ØŸÛ”!\"\\'()-]', '', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "altered_data.iloc[:, 0] = altered_data.iloc[:, 0].apply(clean_text)  \n",
    "altered_data.iloc[:, 1] = altered_data.iloc[:, 1].apply(clean_text)  \n",
    "altered_data.iloc[:, 2] = altered_data.iloc[:, 2].apply(clean_text)  \n",
    "\n",
    "\n",
    "print(\"Evaluating altered dataset...\")\n",
    "altered_f1_scores, altered_results = evaluate_qa_perturbed(altered_data,model, 0,1, 2)\n",
    "\n",
    "altered_results_df = pd.DataFrame(altered_results)\n",
    "\n",
    "altered_results_df.to_csv(\"altered_results.csv\", index=False, encoding='utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6324537,
     "sourceId": 10229201,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6325018,
     "sourceId": 10229857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6329301,
     "sourceId": 10235826,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6330027,
     "sourceId": 10236753,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6331400,
     "sourceId": 10238451,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0873a071fbaa4f6387efd23e7ac39dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1531e600986d4473a7360e88359d1a46",
       "IPY_MODEL_18403d589308493db9ba377090a34c44",
       "IPY_MODEL_89c3740c9c174fd0b17a28e9765fc199"
      ],
      "layout": "IPY_MODEL_4e6a7b499cc747f289e5207d00e30a3d"
     }
    },
    "0fc4295793354da6a173c6ade75dbbbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1531e600986d4473a7360e88359d1a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73e8e9a937974d9f9285cf88af5b0120",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b9a8e2eecee44423ba75d030f948cf0f",
      "value": "Map:â€‡100%"
     }
    },
    "18403d589308493db9ba377090a34c44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c3d5bee60684097b1769b85055d2ba0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_485bb599b71947e3b4e882d6e2033120",
      "value": 100
     }
    },
    "18aaa42f4a4a4b109b0f58c823ede3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cfd23a98804975bb6dcb25f348946c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c3d5bee60684097b1769b85055d2ba0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3eb4a29511184341ac5c514d1e8738c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e666a8b7ebb14b4aa7589f1a1bc37157",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b8130811f37a439b95a9b7507145a191",
      "value": "Map:â€‡100%"
     }
    },
    "46eb6063b3754f45996a5f3e84817f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3eb4a29511184341ac5c514d1e8738c1",
       "IPY_MODEL_7e3d0cc15e4e4ea4a4a5e2400ef68b64",
       "IPY_MODEL_fd71120efd6a4c29ac659d43d5cdb8e9"
      ],
      "layout": "IPY_MODEL_f0b344279c7e4cb29304132460ba70a1"
     }
    },
    "485bb599b71947e3b4e882d6e2033120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e6a7b499cc747f289e5207d00e30a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e0e0f1196fc4f3bbed292f0f3de93a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60a8977d11e1469bacb832507022f35a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73e8e9a937974d9f9285cf88af5b0120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e3d0cc15e4e4ea4a4a5e2400ef68b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18aaa42f4a4a4b109b0f58c823ede3e5",
      "max": 900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_60a8977d11e1469bacb832507022f35a",
      "value": 900
     }
    },
    "89c3740c9c174fd0b17a28e9765fc199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20cfd23a98804975bb6dcb25f348946c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e0e0f1196fc4f3bbed292f0f3de93a0",
      "value": "â€‡100/100â€‡[00:00&lt;00:00,â€‡304.21â€‡examples/s]"
     }
    },
    "b8130811f37a439b95a9b7507145a191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9a8e2eecee44423ba75d030f948cf0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e666a8b7ebb14b4aa7589f1a1bc37157": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b344279c7e4cb29304132460ba70a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f59386a1cd414a979006522ad13fdac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd71120efd6a4c29ac659d43d5cdb8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fc4295793354da6a173c6ade75dbbbf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f59386a1cd414a979006522ad13fdac4",
      "value": "â€‡900/900â€‡[00:02&lt;00:00,â€‡448.52â€‡examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# AI for All: Testing the Robustness of Low-Resource QA Models in Multilingual and Low-Resource Contexts

Abstract
Recent advancements in Natural Language
Processing (NLP) have showcased the transformative potential of transformers and large language models (LLMs) across various domains. However, their accessibility and performance in
low-resource languages and low-resource computational settings remain significant challenges. This study focuses on evaluating lightweight, open-source transformer models and LLMs in low-resource contexts, 
particularly for question answering (Q/A) tasks in English, Urdu, Sindhi, and Pashto. To facilitate this evaluation, we translated a subset of the Stanford SQuAD 2.0 dataset into
Sindhi and Pashto, addressing the scarcity of benchmark datasets for these underrepresented languages. Model performance was analyzed on standard Q/A tasks and subjected to adversarial
perturbations to assess robustness. Additionally, we investigated the susceptibility of these models to jailbreaking via adversarial prompts across the four languages, highlighting potential vulnerabilities 
and biases in low-resource linguistic settings. Our findings reveal the capabilities and limitations of small-scale transformers and opensource LLMs in handling low-resource languages,
providing insights into their feasibility for augmenting real-world applications in underprivileged linguistic communities. By focusing on lightweight models and low-resource settings, this
work contributes to bridging the technological gap in NLP for underserved languages.

#Research Paper Link: [AI for ALL](https://drive.google.com/file/d/1XLFHhrBr9UHI94X6NTPOnJCV7UjwEDmy/view?usp=sharing)


{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/facebookresearch/seamless_communication.git && cd seamless_communication && pip install ."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n"]},{"cell_type":"markdown","metadata":{},"source":["**Facebook m4t Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-12-16T21:03:59.176253Z","iopub.status.busy":"2024-12-16T21:03:59.176022Z","iopub.status.idle":"2024-12-16T21:08:18.022635Z","shell.execute_reply":"2024-12-16T21:08:18.021597Z","shell.execute_reply.started":"2024-12-16T21:03:59.176227Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"254f4aec25f546e3b8d7c3b69a2e8429","version_major":2,"version_minor":0},"text/plain":["preprocessor_config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5219d4f3c8854c70bf7e8ca22680095c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/19.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e29beb1f6fb947279daaf99a8eb35af8","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.17M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d69d4acaf73c4889809a8b7907b557ab","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41bf86dfcc4946848a7387ce65a9242d","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93ffe01800124d848e9e9619ca4e248d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/2.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da8ac6feafe84d4f9299db7fe8ce28d4","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/211k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52c9e344e1e345cb8fd6f1bd1fc6d54f","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a73860d3e22437db1e3ae4ae268a0ed","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8c52f1395294499807e2f475f27c50f","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/4.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d42645b79614eecb4083d476809c8d6","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51ab97d92d0c4c4f9dad42737ac3fe7b","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/9.91M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["SeamlessM4Tv2Model(\n","  (shared): Embedding(256102, 1024, padding_idx=0)\n","  (text_encoder): SeamlessM4Tv2Encoder(\n","    (embed_tokens): SeamlessM4Tv2ScaledWordEmbedding(256102, 1024, padding_idx=0)\n","    (embed_positions): SeamlessM4Tv2SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0-23): 24 x SeamlessM4Tv2EncoderLayer(\n","        (self_attn): SeamlessM4Tv2Attention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (attn_dropout): Dropout(p=0.1, inplace=False)\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (ffn): SeamlessM4Tv2FeedForwardNetwork(\n","          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (act): ReLU()\n","        )\n","        (ffn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (ffn_dropout): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (speech_encoder): SeamlessM4Tv2SpeechEncoder(\n","    (feature_projection): SeamlessM4Tv2ConformerFeatureProjection(\n","      (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","      (projection): Linear(in_features=160, out_features=1024, bias=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): SeamlessM4Tv2ConformerEncoder(\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (layers): ModuleList(\n","        (0-23): 24 x SeamlessM4Tv2ConformerEncoderLayer(\n","          (ffn1_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (ffn1): SeamlessM4Tv2ConformerFeedForward(\n","            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n","            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): SiLU()\n","            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (output_dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (self_attn_dropout): Dropout(p=0.0, inplace=False)\n","          (self_attn): SeamlessM4Tv2ConformerSelfAttention(\n","            (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (distance_embedding): Embedding(73, 64)\n","          )\n","          (conv_module): SeamlessM4Tv2ConformerConvolutionModule(\n","            (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n","            (glu): GLU(dim=1)\n","            (depthwise_conv): Conv1d(1024, 1024, kernel_size=(31,), stride=(1,), groups=1024, bias=False)\n","            (depthwise_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (activation): SiLU()\n","            (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (ffn2_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (ffn2): SeamlessM4Tv2ConformerFeedForward(\n","            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n","            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): SiLU()\n","            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (output_dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (intermediate_ffn): SeamlessM4Tv2ConformerFeedForward(\n","      (intermediate_dropout): Dropout(p=0.0, inplace=False)\n","      (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n","      (intermediate_act_fn): ReLU()\n","      (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n","      (output_dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (adapter): SeamlessM4Tv2ConformerAdapter(\n","      (layers): ModuleList(\n","        (0): SeamlessM4Tv2ConformerAdapterLayer(\n","          (residual_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (residual_conv): Conv1d(1024, 2048, kernel_size=(8,), stride=(8,), padding=(4,))\n","          (activation): GLU(dim=1)\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (self_attn_conv): Conv1d(1024, 2048, kernel_size=(8,), stride=(8,), padding=(4,))\n","          (self_attn): SeamlessM4Tv2ConformerSelfAttention(\n","            (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n","            (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_dropout): Dropout(p=0.1, inplace=False)\n","          (ffn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (ffn): SeamlessM4Tv2ConformerFeedForward(\n","            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n","            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): ReLU()\n","            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (output_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (inner_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (text_decoder): SeamlessM4Tv2Decoder(\n","    (embed_tokens): SeamlessM4Tv2ScaledWordEmbedding(256102, 1024, padding_idx=0)\n","    (embed_positions): SeamlessM4Tv2SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0-23): 24 x SeamlessM4Tv2DecoderLayer(\n","        (self_attn): SeamlessM4Tv2Attention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (activation_fn): ReLU()\n","        (attn_dropout): Dropout(p=0.1, inplace=False)\n","        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (cross_attention): SeamlessM4Tv2Attention(\n","          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        )\n","        (cross_attention_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (ffn): SeamlessM4Tv2FeedForwardNetwork(\n","          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (act): ReLU()\n","        )\n","        (ffn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (ffn_dropout): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=256102, bias=False)\n","  (t2u_model): SeamlessM4Tv2TextToUnitForConditionalGeneration(\n","    (model): SeamlessM4Tv2TextToUnitModel(\n","      (encoder): SeamlessM4Tv2Encoder(\n","        (layers): ModuleList(\n","          (0-5): 6 x SeamlessM4Tv2EncoderLayer(\n","            (self_attn): SeamlessM4Tv2Attention(\n","              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (ffn): SeamlessM4Tv2FeedForwardNetwork(\n","              (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n","              (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","              (act): ReLU()\n","            )\n","            (ffn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (ffn_dropout): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (decoder): SeamlessM4Tv2TextToUnitDecoder(\n","        (embed_tokens): Embedding(10082, 1024, padding_idx=1)\n","        (embed_char): Embedding(10943, 1024)\n","        (embed_char_positions): SeamlessM4Tv2SinusoidalPositionalEmbedding()\n","        (duration_predictor): SeamlessM4Tv2VariancePredictor(\n","          (conv1): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=same)\n","          (activation_fuction): ReLU()\n","          (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): Dropout(p=0.5, inplace=False)\n","          (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n","          (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (proj): Linear(in_features=256, out_features=1, bias=True)\n","        )\n","        (embed_positions): SeamlessM4Tv2SinusoidalPositionalEmbedding()\n","        (layers): ModuleList(\n","          (0-5): 6 x SeamlessM4Tv2TextToUnitDecoderLayer(\n","            (self_attn): SeamlessM4Tv2Attention(\n","              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (conv1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=same)\n","            (activation_fn): ReLU()\n","            (conv2): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=same)\n","            (conv_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (conv_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (lm_head): Linear(in_features=1024, out_features=10082, bias=False)\n","  )\n","  (vocoder): SeamlessM4Tv2CodeHifiGan(\n","    (dur_predictor): SeamlessM4Tv2VariancePredictor(\n","      (conv1): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=same)\n","      (activation_fuction): ReLU()\n","      (ln1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","      (dropout_module): Dropout(p=0.5, inplace=False)\n","      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(1,), padding=same)\n","      (ln2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","      (proj): Linear(in_features=1280, out_features=1, bias=True)\n","    )\n","    (unit_embedding): Embedding(10000, 1280)\n","    (speaker_embedding): Embedding(200, 256)\n","    (language_embedding): Embedding(36, 256)\n","    (hifi_gan): SeamlessM4Tv2HifiGan(\n","      (conv_pre): Conv1d(1792, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n","      (upsampler): ModuleList(\n","        (0): ConvTranspose1d(512, 256, kernel_size=(11,), stride=(5,), padding=(3,))\n","        (1): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,), padding=(2,))\n","        (2): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,), padding=(2,))\n","        (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n","        (4): ConvTranspose1d(32, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n","      )\n","      (resblocks): ModuleList(\n","        (0): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n","            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n","            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n","          )\n","        )\n","        (1): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n","            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n","            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n","          )\n","        )\n","        (2): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n","            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n","            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n","          )\n","        )\n","        (3): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n","            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n","            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n","          )\n","        )\n","        (4): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n","            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n","            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n","          )\n","        )\n","        (5): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n","            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n","            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n","          )\n","        )\n","        (6): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n","            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","          )\n","        )\n","        (7): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n","            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n","            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n","          )\n","        )\n","        (8): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n","            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n","            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n","          )\n","        )\n","        (9): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n","            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n","            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n","          )\n","        )\n","        (10): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n","            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n","            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n","          )\n","        )\n","        (11): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n","            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n","            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n","          )\n","        )\n","        (12): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n","            (1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n","            (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n","          )\n","        )\n","        (13): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n","            (1): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n","            (2): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n","          )\n","        )\n","        (14): HifiGanResidualBlock(\n","          (convs1): ModuleList(\n","            (0): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n","            (1): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n","            (2): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n","          )\n","          (convs2): ModuleList(\n","            (0-2): 3 x Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n","          )\n","        )\n","      )\n","      (conv_post): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n","    )\n","  )\n",")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import AutoProcessor, SeamlessM4Tv2Model\n","\n","processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n","model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-16T21:08:47.577220Z","iopub.status.busy":"2024-12-16T21:08:47.576872Z","iopub.status.idle":"2024-12-16T21:08:48.054998Z","shell.execute_reply":"2024-12-16T21:08:48.054106Z","shell.execute_reply.started":"2024-12-16T21:08:47.577187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Translated Text: زه سبا اسلام آباد ته ځم\n"]}],"source":["#snd (sindhi) and pbt (pashto)\n","english_text = \"I am going to islamabad tomorrow\"\n","\n","text_inputs = processor(text=english_text, src_lang=\"eng\", return_tensors=\"pt\").to(device)\n","output_tokens = model.generate(**text_inputs, tgt_lang=\"pbt\", generate_speech=False)\n","translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n","print(\"Translated Text:\", translated_text)"]},{"cell_type":"markdown","metadata":{},"source":["**Translation Pipepline + Data Proceccsing**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-16T21:11:25.534798Z","iopub.status.busy":"2024-12-16T21:11:25.534443Z","iopub.status.idle":"2024-12-16T21:11:25.546938Z","shell.execute_reply":"2024-12-16T21:11:25.545862Z","shell.execute_reply.started":"2024-12-16T21:11:25.534767Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model is running on device: cuda\n"]}],"source":["import pandas as pd\n","import re\n","import ast\n","from tqdm import tqdm\n","import torch\n","from transformers import AutoProcessor, SeamlessM4Tv2Model\n","\n","SRC_LANG = \"eng\"  # Source language code\n","TGT_LANG = \"pbt\"  # Target language code\n","\n","print(f\"Model is running on device: {device}\")\n","def translate_m4t(processor, model, text, tgt_lang=TGT_LANG, src_lang=SRC_LANG):\n","    text_inputs = processor(text=text, src_lang=src_lang, return_tensors=\"pt\").to(device)\n","    output_tokens = model.generate(**text_inputs, tgt_lang=tgt_lang, generate_speech=False)\n","    translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n","    return translated_text\n","\n","def translate(processor, model, SQuAD, chunk_size=1000):\n","    total_rows = len(SQuAD)\n","\n","    for chunk_start in tqdm(range(0, total_rows, chunk_size), desc=\"Processing chunks\", ncols=100):\n","        chunk_end = min(chunk_start + chunk_size, total_rows)\n","        subset = SQuAD.iloc[chunk_start:chunk_end]\n","        \n","        rows = []\n","        for j in tqdm(range(len(subset)), desc=f\"Processing rows {chunk_start + 1} to {chunk_end}\", ncols=100):\n","            data_num = subset.iloc[j][\"data_num\"]\n","            paragraph_num = subset.iloc[j][\"paragraph_num\"]\n","            id = subset.iloc[j][\"id\"]\n","            title = subset.iloc[j][\"title\"]\n","            context = ast.literal_eval(subset.iloc[j][\"context\"])\n","            question = subset.iloc[j][\"question\"]\n","            is_impossible = subset.iloc[j][\"is_impossible\"]\n","            \n","            title_ = translate_m4t(processor, model, title)\n","            question_ = translate_m4t(processor, model, question)\n","\n","            context_ = []\n","            review = True\n","            for sentence in context:\n","                if \"••\" in sentence:\n","                    sentence = re.sub(\"••'\", \"\\\"\", sentence)\n","                    sentence = re.sub(\"'••\", \"\\\"\", sentence)\n","                    sentence = re.sub(\"••\", \"\\\"\", sentence)\n","                sentence_ = translate_m4t(processor, model, sentence)\n","                if sentence_.count(\"\\\"\") == 2:\n","                    sentence_ = re.sub(\"\\\"\", \"••\", sentence_)\n","                    review = False\n","                context_.append(sentence_)\n","\n","            context_ = \" \".join(context_)\n","            row = (data_num, paragraph_num, id, title_, context_, question_, is_impossible, review)\n","            rows.append(row)\n","\n","        df_translated = pd.DataFrame(rows, columns=[\"data_num\", \"paragraph_num\", \"id\", \"title\", \"context\",\n","                                                    \"question\", \"is_impossible\", \"review\"])\n","\n","        output_path = f\"/kaggle/working/SQuAD_Translated_{chunk_start // chunk_size + 1}.csv\"\n","        df_translated.to_csv(output_path, index=False)\n","        print(f\"Saved translated data for chunk {chunk_start // chunk_size + 1} to {output_path}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-12-16T21:12:36.923865Z","iopub.status.busy":"2024-12-16T21:12:36.923185Z","iopub.status.idle":"2024-12-16T21:15:40.586297Z","shell.execute_reply":"2024-12-16T21:15:40.584627Z","shell.execute_reply.started":"2024-12-16T21:12:36.923830Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing chunks:   0%|                                                   | 0/2000 [00:00<?, ?it/s]\n","Processing rows 1 to 10:   0%|                                               | 0/10 [00:00<?, ?it/s]\u001b[A\n","Processing rows 1 to 10:  10%|███▉                                   | 1/10 [00:02<00:24,  2.75s/it]\u001b[A\n","Processing rows 1 to 10:  20%|███████▊                               | 2/10 [00:13<01:00,  7.60s/it]\u001b[A\n","Processing rows 1 to 10:  30%|███████████▋                           | 3/10 [00:24<01:03,  9.02s/it]\u001b[A\n","Processing rows 1 to 10:  40%|███████████████▌                       | 4/10 [00:34<00:56,  9.45s/it]\u001b[A\n","Processing rows 1 to 10:  50%|███████████████████▌                   | 5/10 [00:38<00:36,  7.29s/it]\u001b[A\n","Processing rows 1 to 10:  60%|███████████████████████▍               | 6/10 [00:41<00:23,  5.96s/it]\u001b[A\n","Processing rows 1 to 10:  70%|███████████████████████████▎           | 7/10 [00:44<00:15,  5.05s/it]\u001b[A\n","Processing rows 1 to 10:  80%|███████████████████████████████▏       | 8/10 [00:50<00:10,  5.45s/it]\u001b[A\n","Processing rows 1 to 10:  90%|███████████████████████████████████    | 9/10 [01:02<00:07,  7.36s/it]\u001b[A\n","Processing rows 1 to 10: 100%|██████████████████████████████████████| 10/10 [01:09<00:00,  7.00s/it]\u001b[A\n","Processing chunks:   0%|                                        | 1/2000 [01:09<38:51:05, 69.97s/it]"]},{"name":"stdout","output_type":"stream","text":["Saved translated data for chunk 1 to /kaggle/working/SQuAD_Translated_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n","Processing rows 11 to 20:   0%|                                              | 0/10 [00:00<?, ?it/s]\u001b[A\n","Processing rows 11 to 20:  10%|███▊                                  | 1/10 [00:04<00:41,  4.57s/it]\u001b[A\n","Processing rows 11 to 20:  20%|███████▌                              | 2/10 [00:09<00:40,  5.05s/it]\u001b[A\n","Processing rows 11 to 20:  30%|███████████▍                          | 3/10 [00:15<00:36,  5.17s/it]\u001b[A\n","Processing rows 11 to 20:  40%|███████████████▏                      | 4/10 [00:20<00:30,  5.16s/it]\u001b[A\n","Processing rows 11 to 20:  50%|███████████████████                   | 5/10 [00:25<00:26,  5.24s/it]\u001b[A\n","Processing rows 11 to 20:  60%|██████████████████████▊               | 6/10 [00:31<00:20,  5.24s/it]\u001b[A\n","Processing rows 11 to 20:  70%|██████████████████████████▌           | 7/10 [00:41<00:20,  6.82s/it]\u001b[A\n","Processing rows 11 to 20:  80%|██████████████████████████████▍       | 8/10 [00:47<00:13,  6.75s/it]\u001b[A\n","Processing rows 11 to 20:  90%|██████████████████████████████████▏   | 9/10 [00:54<00:06,  6.82s/it]\u001b[A\n","Processing rows 11 to 20: 100%|█████████████████████████████████████| 10/10 [01:01<00:00,  6.17s/it]\u001b[A\n","Processing chunks:   0%|                                        | 2/2000 [02:11<36:08:00, 65.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Saved translated data for chunk 2 to /kaggle/working/SQuAD_Translated_2.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n","Processing rows 21 to 30:   0%|                                              | 0/10 [00:00<?, ?it/s]\u001b[A\n","Processing rows 21 to 30:  10%|███▊                                  | 1/10 [00:06<00:56,  6.33s/it]\u001b[A\n","Processing rows 21 to 30:  20%|███████▌                              | 2/10 [00:10<00:40,  5.01s/it]\u001b[A\n","Processing rows 21 to 30:  30%|███████████▍                          | 3/10 [00:16<00:37,  5.34s/it]\u001b[A\n","Processing rows 21 to 30:  40%|███████████████▏                      | 4/10 [00:21<00:32,  5.48s/it]\u001b[A\n","Processing rows 21 to 30:  50%|███████████████████                   | 5/10 [00:27<00:27,  5.51s/it]\u001b[A\n","Processing rows 21 to 30:  60%|██████████████████████▊               | 6/10 [00:51<00:34,  8.57s/it]\u001b[A\n","Processing chunks:   0%|                                        | 2/2000 [03:03<50:48:19, 91.54s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load SQuAD datasets and translate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m SQuAD_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/squadsubsetenglish/SquadSubset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSQuAD_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# SQuAD_dev = pd.read_csv(\"/SQuAD/dev-v2.0-clean.csv\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# translate(processor, model, SQuAD_dev, list(range(0, 35)))\u001b[39;00m\n","Cell \u001b[0;32mIn[6], line 57\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(processor, model, SQuAD, chunk_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m••\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sentence)\n\u001b[1;32m     56\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m••\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sentence)\n\u001b[0;32m---> 57\u001b[0m sentence_ \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_m4t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentence_\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     59\u001b[0m     sentence_ \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m••\u001b[39m\u001b[38;5;124m\"\u001b[39m, sentence_)\n","Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mtranslate_m4t\u001b[0;34m(processor, model, text, tgt_lang, src_lang)\u001b[0m\n\u001b[1;32m     16\u001b[0m text_inputs \u001b[38;5;241m=\u001b[39m processor(text\u001b[38;5;241m=\u001b[39mtext, src_lang\u001b[38;5;241m=\u001b[39msrc_lang, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Generate translated text\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_speech\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Decode the translated text\u001b[39;00m\n\u001b[1;32m     20\u001b[0m translated_text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(output_tokens[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4575\u001b[0m, in \u001b[0;36mSeamlessM4Tv2Model.generate\u001b[0;34m(self, input_ids, input_features, return_intermediate_token_ids, tgt_lang, speaker_id, generate_speech, **kwargs)\u001b[0m\n\u001b[1;32m   4573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_modality(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4575\u001b[0m     text_generation_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4576\u001b[0m sequences \u001b[38;5;241m=\u001b[39m text_generation_output\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m   4578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m generate_speech:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:4407\u001b[0m, in \u001b[0;36mSeamlessM4Tv2Model.forward\u001b[0;34m(self, input_ids, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   4402\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m _compute_new_attention_mask(\n\u001b[1;32m   4403\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m], seq_lens\u001b[38;5;241m=\u001b[39msub_sampled_lengths\n\u001b[1;32m   4404\u001b[0m     )\n\u001b[1;32m   4406\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 4407\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4408\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4416\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4420\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(decoder_outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   4422\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:2132\u001b[0m, in \u001b[0;36mSeamlessM4Tv2Decoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   2122\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   2123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2129\u001b[0m         use_cache,\n\u001b[1;32m   2130\u001b[0m     )\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2132\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2141\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1292\u001b[0m, in \u001b[0;36mSeamlessM4Tv2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m   1290\u001b[0m self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m-> 1292\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_dropout(hidden_states)\n\u001b[1;32m   1299\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py:1100\u001b[0m, in \u001b[0;36mSeamlessM4Tv2Attention.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, past_key_value, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1101\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(current_states))\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["SQuAD_train = pd.read_csv(\"/kaggle/input/squadsubsetenglish/SquadSubset.csv\")\n","translate(processor, model, SQuAD_train, chunk_size=10)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-16T21:32:23.830875Z","iopub.status.busy":"2024-12-16T21:32:23.830550Z","iopub.status.idle":"2024-12-16T21:32:51.309006Z","shell.execute_reply":"2024-12-16T21:32:51.308162Z","shell.execute_reply.started":"2024-12-16T21:32:23.830846Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Translating subset of data: 1/1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:27<00:00,  5.45s/it]"]},{"name":"stdout","output_type":"stream","text":["Saved translated data for subset 1 to /kaggle/working/SQuAD_Translated_subset_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import pandas as pd\n","import re\n","import ast\n","from tqdm import tqdm\n","import torch\n","from transformers import AutoProcessor, SeamlessM4Tv2Model\n","\n","SRC_LANG = \"eng\"  # Source language code\n","TGT_LANG = \"snd\"  # Target language code\n","\n","def translate_m4t(processor, model, text, tgt_lang=TGT_LANG, src_lang=SRC_LANG):\n","    text_inputs = processor(text=text, src_lang=src_lang, return_tensors=\"pt\").to(device)\n","    output_tokens = model.generate(**text_inputs, tgt_lang=tgt_lang, generate_speech=False)\n","    translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n","    return translated_text\n","\n","def translate_subset(processor, model, SQuAD, data, subset_size=5, output_dir=\"/kaggle/working\"):\n","    for i in data:\n","        print(f\"Translating subset of data: {(i + 1)}/{len(data)}\")\n","        df = SQuAD[SQuAD[\"data_num\"] == i].head(subset_size)  \n","        rows = []\n","        for j in tqdm(range(len(df))):\n","            data_num = df.iloc[j][\"data_num\"]\n","            paragraph_num = df.iloc[j][\"paragraph_num\"]\n","            id = df.iloc[j][\"id\"]\n","            title = df.iloc[j][\"title\"]\n","            context = ast.literal_eval(df.iloc[j][\"context\"])\n","            question = df.iloc[j][\"question\"]\n","            is_impossible = df.iloc[j][\"is_impossible\"]\n","            title_ = translate_m4t(processor, model, title)\n","            question_ = translate_m4t(processor, model, question)\n","\n","            context_ = []\n","            review = True\n","            for sentence in context:\n","                if \"••\" in sentence:\n","                    sentence = re.sub(\"••'\", \"\\\"\", sentence)\n","                    sentence = re.sub(\"'••\", \"\\\"\", sentence)\n","                    sentence = re.sub(\"••\", \"\\\"\", sentence)\n","                sentence_ = translate_m4t(processor, model, sentence)\n","                if sentence_.count(\"\\\"\") == 2:\n","                    sentence_ = re.sub(\"\\\"\", \"••\", sentence_)\n","                    review = False\n","                context_.append(sentence_)\n","\n","            context_ = \" \".join(context_)\n","            row = (data_num, paragraph_num, id, title_, context_, question_, is_impossible, review)\n","            rows.append(row)\n","\n","        df_translated = pd.DataFrame(rows, columns=[\"data_num\", \"paragraph_num\", \"id\", \"title\", \"context\",\n","                                                    \"question\", \"is_impossible\", \"review\"])\n","        output_path = f\"{output_dir}/SQuAD_Translated_subset_{i + 1}.csv\"\n","        df_translated.to_csv(output_path, index=False)\n","        print(f\"Saved translated data for subset {i + 1} to {output_path}\")\n","\n","SQuAD_train = pd.read_csv(\"/kaggle/input/squadsubsetenglish/SquadSubset.csv\")\n","translate_subset(processor, model, SQuAD_train, list(range(0, 1)), subset_size=5)  "]},{"cell_type":"markdown","metadata":{},"source":["**Google Translate API**"]},{"cell_type":"markdown","metadata":{},"source":["Testing"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Text: \"Beyoncé Giselle Knowles-Carter (/biː'jɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame ••in the late 1990s•• as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles Crazy in Love and Baby Boy.\"\n","Translation: &quot;بیونسي ګیزیل نولس-کارټر (/biː&#39;jɒnseɪ/ bee-YON-say) (د سپتمبر 4، 1981 زیږیدلی) یو امریکایی سندرغاړی، سندرغاړی، ریکارډ جوړونکی او لوبغاړی دی. په هوسټن، ټیکساس کې زیږیدلی او لوی شوی، هغې په مختلفو سندرو کې سندرې ترسره کړې. او د ماشوم په توګه د نڅا سیالۍ، او په وروستیو کې شهرت ته وده ورکړه 1990•• د R&amp;B د نجونو ګروپ د اصلي سندرغاړي په توګه د خپل پلار، میتیو نولس لخوا اداره کیږي، دا ډله د نړۍ ترټولو غوره پلورونکي ګروپونو څخه وګرځیده، د بیونس لومړی البوم، په خطر کې مینه (2003)، چې هغه یې په ټوله نړۍ کې د یو واحد هنرمند په توګه رامینځته کړه، پنځه ګرامي جایزې ترلاسه کړې او د بلبورډ هوټ 100 نمبر 1 واحد سندرغاړی Crazy in Love and Baby Boy.\n","Detected source language: en\n","{'translatedText': '&quot;بیونسي ګیزیل نولس-کارټر (/biː&#39;jɒnseɪ/ bee-YON-say) (د سپتمبر 4، 1981 زیږیدلی) یو امریکایی سندرغاړی، سندرغاړی، ریکارډ جوړونکی او لوبغاړی دی. په هوسټن، ټیکساس کې زیږیدلی او لوی شوی، هغې په مختلفو سندرو کې سندرې ترسره کړې. او د ماشوم په توګه د نڅا سیالۍ، او په وروستیو کې شهرت ته وده ورکړه 1990•• د R&amp;B د نجونو ګروپ د اصلي سندرغاړي په توګه د خپل پلار، میتیو نولس لخوا اداره کیږي، دا ډله د نړۍ ترټولو غوره پلورونکي ګروپونو څخه وګرځیده، د بیونس لومړی البوم، په خطر کې مینه (2003)، چې هغه یې په ټوله نړۍ کې د یو واحد هنرمند په توګه رامینځته کړه، پنځه ګرامي جایزې ترلاسه کړې او د بلبورډ هوټ 100 نمبر 1 واحد سندرغاړی Crazy in Love and Baby Boy.', 'detectedSourceLanguage': 'en', 'input': '\"Beyoncé Giselle Knowles-Carter (/biː\\'jɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame ••in the late 1990s•• as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles Crazy in Love and Baby Boy.\"'}\n"]}],"source":["from google.cloud import translate_v2 as translate\n","\n","def translate_text(target: str, text: str) -> dict:\n","    \"\"\"Translates text into the target language.\n","\n","    Target must be an ISO 639-1 language code.\n","    \"\"\"\n","    translate_client = translate.Client()\n","\n","    if isinstance(text, bytes):\n","        text = text.decode(\"utf-8\")\n","\n","    result = translate_client.translate(text, target_language=target)\n","\n","    print(\"Text: {}\".format(result[\"input\"]))\n","    print(\"Translation: {}\".format(result[\"translatedText\"]))\n","    print(\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n","\n","    return result\n","\n","import os\n","os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/\"\n","\n","target_language = \"ps\"  # Spanish\n","text_to_translate = \"Hello, world!\"\n","\n","response = translate_text(target_language, text_to_translate)\n","print(response)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6313814,"sourceId":10214978,"sourceType":"datasetVersion"},{"datasetId":6316080,"sourceId":10217818,"sourceType":"datasetVersion"},{"datasetId":602944,"sourceId":1082295,"sourceType":"datasetVersion"}],"dockerImageVersionId":30805,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}

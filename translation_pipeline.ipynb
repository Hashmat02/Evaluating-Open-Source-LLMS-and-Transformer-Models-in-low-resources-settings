{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, SeamlessM4Tv2Model\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/seamless_communication.git && cd seamless_communication && pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = \"I am going to islamabad tomorrow\"\n",
    "text_inputs = processor(text=english_text, src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "output_tokens = model.generate(**text_inputs, tgt_lang=\"pbt\", generate_speech=False)\n",
    "translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Translated Text in Pashto:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squad Translation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANG = \"eng\"  # Source language code\n",
    "TGT_LANG = \"urd\"  # Target language code\n",
    "\n",
    "def translate_m4t(processor, model, text, tgt_lang=TGT_LANG, src_lang=SRC_LANG):\n",
    "    text_inputs = processor(text=text, src_lang=src_lang, return_tensors=\"pt\").to(device)\n",
    "    output_tokens = model.generate(**text_inputs, tgt_lang=tgt_lang, generate_speech=False)\n",
    "    translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def translate(processor, model, SQuAD, data):\n",
    "    for i in data:\n",
    "        print(f\"Translating data: {(i + 1)}/{len(data)}\")\n",
    "        df = SQuAD[SQuAD[\"data_num\"] == i]\n",
    "        rows = []\n",
    "        for j in tqdm(range(len(df))):\n",
    "            data_num = df.iloc[j][\"data_num\"]\n",
    "            paragraph_num = df.iloc[j][\"paragraph_num\"]\n",
    "            id = df.iloc[j][\"id\"]\n",
    "            title = df.iloc[j][\"title\"]\n",
    "            context = ast.literal_eval(df.iloc[j][\"context\"])\n",
    "            question = df.iloc[j][\"question\"]\n",
    "            is_impossible = df.iloc[j][\"is_impossible\"]\n",
    "\n",
    "            title_ = translate_m4t(processor, model, title)\n",
    "            question_ = translate_m4t(processor, model, question)\n",
    "\n",
    "            context_ = []\n",
    "            review = True\n",
    "            for sentence in context:\n",
    "                if \"••\" in sentence:\n",
    "                    sentence = re.sub(\"••'\", \"\\\"\", sentence)\n",
    "                    sentence = re.sub(\"'••\", \"\\\"\", sentence)\n",
    "                    sentence = re.sub(\"••\", \"\\\"\", sentence)\n",
    "                sentence_ = translate_m4t(processor, model, sentence)\n",
    "                if sentence_.count(\"\\\"\") == 2:\n",
    "                    sentence_ = re.sub(\"\\\"\", \"••\", sentence_)\n",
    "                    review = False\n",
    "                context_.append(sentence_)\n",
    "\n",
    "            context_ = \" \".join(context_)\n",
    "            row = (data_num, paragraph_num, id, title_, context_, question_, is_impossible, review)\n",
    "            rows.append(row)\n",
    "\n",
    "        df_translated = pd.DataFrame(rows, columns=[\"data_num\", \"paragraph_num\", \"id\", \"title\", \"context\",\n",
    "                                                    \"question\", \"is_impossible\", \"review\"])\n",
    "        df_translated.to_csv(f\"SQuAD-UR/train-v2.0/{i}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQuAD_train = pd.read_csv(\"/SQuAD/train-v2.0-clean.csv\")\n",
    "translate(processor, model, SQuAD_train, list(range(0, 442)))\n",
    "\n",
    "SQuAD_dev = pd.read_csv(\"/SQuAD/dev-v2.0-clean.csv\")\n",
    "translate(processor, model, SQuAD_dev, list(range(0, 35)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10225337,"sourceType":"datasetVersion","datasetId":6321621}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install openai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:37:28.286474Z","iopub.execute_input":"2024-12-17T18:37:28.286898Z","iopub.status.idle":"2024-12-17T18:37:38.752529Z","shell.execute_reply.started":"2024-12-17T18:37:28.286861Z","shell.execute_reply":"2024-12-17T18:37:38.750949Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.57.4)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nfrom openai import OpenAI\nimport json\nimport time\nimport os\n\nclient = OpenAI(api_key = \"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\")\n\ndef generate_prompt(context, question, answer):\n    return f\"\"\"\nYou are tasked with perturbing a given context and question while ensuring the answer remains intact. Use the following techniques:\n\n1. **Synonym Replacement**: Replace words in the context and question with appropriate synonyms where possible.\n2. **Paraphrasing**: Rephrase sentences in the context and question to make them different but preserve their meaning.\n\nThe perturbation must:\n- Maintain the overall meaning of the context and question.\n- Ensure the answer remains present and unchanged in the context.\n- Make the question and context look slightly different from the original.\n\n### Input:\n- **Context**: {context}\n- **Question**: {question}\n- **Answer**: {answer}\n\n### Output Format:\nProvide the output in the following json format:\n```\n{{\n  \"perturbed_context\": \"Your perturbed context here\",\n  \"perturbed_question\": \"Your perturbed question here\"\n}}\n```\n\"\"\"\n\ndef call_gpt4(prompt):\n    try:\n        completion = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            response_format = { \"type\": \"json_object\" }\n        )\n      \n\n        content = completion.choices[0].message.content.strip()\n\n        result = json.loads(content)\n        \n        return result\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n\n\n\ndef process_single_sample(row):\n    context = row['context']\n    question = row['question']\n    answer = row['answer']\n    \n    prompt = generate_prompt(context, question, answer)\n    \n    response = call_gpt4(prompt)\n    \n    if response:\n        try:\n            return {\n                \"id\": row['id'],\n                \"title\": row['title'],\n                \"original_context\": context,\n                \"perturbed_context\": response.get(\"perturbed_context\", \"\"),\n                \"original_question\": question,\n                \"perturbed_question\": response.get(\"perturbed_question\", \"\"),\n                \"answer\": answer,\n                \"is_impossible\": row['is_impossible']\n            }\n        except json.JSONDecodeError:\n            print(\"Failed to parse JSON response. Skipping...\")\n            return None\n    else:\n        print(\"No response received. Skipping...\")\n        return None\n\ndef process_dataset(input_file, output_file, max_iterations=1000):\n    data = pd.read_csv(input_file)\n    \n    if not os.path.exists(output_file):\n        pd.DataFrame(columns=data.columns).to_csv(output_file, index=False)\n    \n    processed_count = 0\n    \n    for index, row in data.iterrows():\n        if processed_count >= max_iterations:\n            break  \n        \n        result = process_single_sample(row)\n        \n        if result:\n            pd.DataFrame([result]).to_csv(output_file, mode='a', header=False, index=False)\n            processed_count += 1\n        \n        time.sleep(1)\n    \n    print(f\"Processed {processed_count} samples. Perturbed data saved to {output_file}\")\n\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:38:03.043140Z","iopub.execute_input":"2024-12-17T18:38:03.043556Z","iopub.status.idle":"2024-12-17T18:38:03.072741Z","shell.execute_reply.started":"2024-12-17T18:38:03.043516Z","shell.execute_reply":"2024-12-17T18:38:03.071396Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"input_file = '/kaggle/input/squad-small/smallset.csv'  \noutput_file = \"perturbed_dataset_english.csv\"  \n\nprint(\"Starting batch perturbation process...\")\nprocess_dataset(input_file, output_file)\nprint(\"Batch perturbation complete!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:38:13.550288Z","iopub.execute_input":"2024-12-17T18:38:13.550698Z","iopub.status.idle":"2024-12-17T19:52:20.220964Z","shell.execute_reply.started":"2024-12-17T18:38:13.550657Z","shell.execute_reply":"2024-12-17T19:52:20.219562Z"}},"outputs":[{"name":"stdout","text":"Starting batch perturbation process...\nProcessed 1000 samples. Perturbed data saved to perturbed_dataset_english.csv\nBatch perturbation complete!\n","output_type":"stream"}],"execution_count":23}]}